{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f827d0fc-8f68-4eba-8de0-fbbbaa11cda0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T08:08:48.293942Z",
     "iopub.status.busy": "2023-08-31T08:08:48.293484Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-08-31 16:08:51,548] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "2023-08-31 16:08:51.812508: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "08/31/2023 16:08:52 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "[INFO|configuration_utils.py:667] 2023-08-31 16:08:52,723 >> loading configuration file /mnt/workspace/dataroot/models/michaelwzhu/Chinese-LlaMA2-chat-7B-sft-v0.3/config.json\n",
      "[INFO|configuration_utils.py:725] 2023-08-31 16:08:52,724 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"/mnt/workspace/dataroot/models/michaelwzhu/Chinese-LlaMA2-chat-7B-sft-v0.3\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_length\": 4096,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.30.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 49954\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1821] 2023-08-31 16:08:52,724 >> loading file tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:1821] 2023-08-31 16:08:52,724 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:1821] 2023-08-31 16:08:52,724 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1821] 2023-08-31 16:08:52,724 >> loading file tokenizer_config.json\n",
      "08/31/2023 16:08:53 - INFO - datasets.builder - Using custom data configuration default-bb1f620ea08b00b9\n",
      "08/31/2023 16:08:53 - INFO - datasets.info - Loading Dataset Infos from /opt/conda/lib/python3.8/site-packages/datasets/packaged_modules/json\n",
      "08/31/2023 16:08:53 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
      "08/31/2023 16:08:53 - INFO - datasets.info - Loading Dataset info from /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4\n",
      "08/31/2023 16:08:53 - WARNING - datasets.builder - Found cached dataset json (/mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "08/31/2023 16:08:53 - INFO - datasets.info - Loading Dataset info from /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4\n",
      "100%|████████████████████████████████████████████| 3/3 [00:00<00:00, 676.03it/s]\n",
      "08/31/2023 16:08:53 - INFO - datasets.arrow_dataset - Process #0 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-ce990a6f075b8688_00000_of_00004.arrow\n",
      "08/31/2023 16:08:53 - INFO - datasets.arrow_dataset - Process #1 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-ce990a6f075b8688_00001_of_00004.arrow\n",
      "08/31/2023 16:08:53 - INFO - datasets.arrow_dataset - Process #2 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-ce990a6f075b8688_00002_of_00004.arrow\n",
      "08/31/2023 16:08:53 - INFO - datasets.arrow_dataset - Process #3 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-ce990a6f075b8688_00003_of_00004.arrow\n",
      "08/31/2023 16:08:53 - INFO - datasets.arrow_dataset - Spawning 4 processes\n",
      "Running tokenizer on dataset (num_proc=4):   0%| | 0/82600 [00:00<?, ? examples/08/31/2023 16:08:53 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-ce990a6f075b8688_00000_of_00004.arrow\n",
      "08/31/2023 16:08:53 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-ce990a6f075b8688_00001_of_00004.arrow\n",
      "08/31/2023 16:08:53 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-ce990a6f075b8688_00002_of_00004.arrow\n",
      "08/31/2023 16:08:53 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-ce990a6f075b8688_00003_of_00004.arrow\n",
      "08/31/2023 16:09:30 - INFO - datasets.arrow_dataset - Concatenating 4 shards    \n",
      "08/31/2023 16:09:30 - INFO - datasets.arrow_dataset - Process #0 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-46ecc0fa49ea2f67_00000_of_00004.arrow\n",
      "08/31/2023 16:09:30 - INFO - datasets.arrow_dataset - Process #1 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-46ecc0fa49ea2f67_00001_of_00004.arrow\n",
      "08/31/2023 16:09:30 - INFO - datasets.arrow_dataset - Process #2 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-46ecc0fa49ea2f67_00002_of_00004.arrow\n",
      "08/31/2023 16:09:30 - INFO - datasets.arrow_dataset - Process #3 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-46ecc0fa49ea2f67_00003_of_00004.arrow\n",
      "08/31/2023 16:09:30 - INFO - datasets.arrow_dataset - Spawning 4 processes\n",
      "Running tokenizer on dataset (num_proc=4):   0%| | 0/7656 [00:00<?, ? examples/s08/31/2023 16:09:30 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-46ecc0fa49ea2f67_00000_of_00004.arrow\n",
      "08/31/2023 16:09:30 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-46ecc0fa49ea2f67_00002_of_00004.arrow\n",
      "08/31/2023 16:09:30 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-46ecc0fa49ea2f67_00001_of_00004.arrow\n",
      "08/31/2023 16:09:30 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-46ecc0fa49ea2f67_00003_of_00004.arrow\n",
      "08/31/2023 16:09:34 - INFO - datasets.arrow_dataset - Concatenating 4 shards    \n",
      "08/31/2023 16:09:34 - INFO - datasets.arrow_dataset - Process #0 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-6cc0543c6781e59d_00000_of_00004.arrow\n",
      "08/31/2023 16:09:34 - INFO - datasets.arrow_dataset - Process #1 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-6cc0543c6781e59d_00001_of_00004.arrow\n",
      "08/31/2023 16:09:34 - INFO - datasets.arrow_dataset - Process #2 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-6cc0543c6781e59d_00002_of_00004.arrow\n",
      "08/31/2023 16:09:34 - INFO - datasets.arrow_dataset - Process #3 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-6cc0543c6781e59d_00003_of_00004.arrow\n",
      "08/31/2023 16:09:34 - INFO - datasets.arrow_dataset - Spawning 4 processes\n",
      "Running tokenizer on dataset (num_proc=4):   0%| | 0/7656 [00:00<?, ? examples/s08/31/2023 16:09:34 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-6cc0543c6781e59d_00000_of_00004.arrow\n",
      "08/31/2023 16:09:34 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-6cc0543c6781e59d_00001_of_00004.arrow\n",
      "08/31/2023 16:09:34 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-6cc0543c6781e59d_00002_of_00004.arrow\n",
      "08/31/2023 16:09:34 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-6cc0543c6781e59d_00003_of_00004.arrow\n",
      "08/31/2023 16:09:37 - INFO - datasets.arrow_dataset - Concatenating 4 shards    \n",
      "tokenized_dataset:  DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 82600\n",
      "    })\n",
      "    dev: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 7656\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 7656\n",
      "    })\n",
      "})\n",
      "[1, 29871, 31658, 30383, 13, 32237, 31138, 32380, 36655, 30214, 39313, 34339, 36655, 30275, 34534, 30210, 33942, 37110, 30214, 31666, 37887, 38920, 31149, 39990, 30952, 30383, 13, 36655, 32342, 30383, 13, 32822, 30383, 32593, 41049, 31639, 32269, 43434, 43095, 30210, 32027, 30882, 13, 32822, 30383, 38020, 33096, 30806, 36021, 32822, 31999, 38020, 32764, 32066, 32161, 32058, 30882, 13, 34339, 36655, 30383, 13, 33062, 30383, 31238, 32292, 30850, 32980, 33673, 34982, 43095, 13, 30682, 31333, 39990, 30952, 41133, 30383, 32009, 42147, 31751, 33942, 30214, 42147, 31751, 33942, 30214, 32395, 32237, 35230, 30333, 32932, 35358, 32262, 42147, 31751, 33942, 13, 33091, 30383, 13, 34339, 36655, 32204, 33942, 33858, 39990, 30952, 33933, 30573, 30383, 13, 43095, 30383, 32009, 42147, 31751, 33942, 2]\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 34339, 36655, 32204, 33942, 33858, 39990, 30952, 33933, 30573, 30383, 13, 43095, 30383, 32009, 42147, 31751, 33942, 2]\n",
      "08/31/2023 16:09:37 - INFO - datasets.arrow_dataset - Process #0 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-53f07414ab2782f9_00000_of_00004.arrow\n",
      "08/31/2023 16:09:37 - INFO - datasets.arrow_dataset - Process #1 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-53f07414ab2782f9_00001_of_00004.arrow\n",
      "08/31/2023 16:09:37 - INFO - datasets.arrow_dataset - Process #2 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-53f07414ab2782f9_00002_of_00004.arrow\n",
      "08/31/2023 16:09:37 - INFO - datasets.arrow_dataset - Process #3 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-53f07414ab2782f9_00003_of_00004.arrow\n",
      "08/31/2023 16:09:37 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-53f07414ab2782f9_*_of_00004.arrow\n",
      "08/31/2023 16:09:37 - INFO - datasets.arrow_dataset - Concatenating 4 shards\n",
      "08/31/2023 16:09:38 - INFO - datasets.arrow_dataset - Process #0 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-19b08660c5b0a54e_00000_of_00004.arrow\n",
      "08/31/2023 16:09:38 - INFO - datasets.arrow_dataset - Process #1 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-19b08660c5b0a54e_00001_of_00004.arrow\n",
      "08/31/2023 16:09:38 - INFO - datasets.arrow_dataset - Process #2 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-19b08660c5b0a54e_00002_of_00004.arrow\n",
      "08/31/2023 16:09:38 - INFO - datasets.arrow_dataset - Process #3 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-19b08660c5b0a54e_00003_of_00004.arrow\n",
      "08/31/2023 16:09:38 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-19b08660c5b0a54e_*_of_00004.arrow\n",
      "08/31/2023 16:09:38 - INFO - datasets.arrow_dataset - Concatenating 4 shards\n",
      "08/31/2023 16:09:38 - INFO - datasets.arrow_dataset - Process #0 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-203d597da0723f71_00000_of_00004.arrow\n",
      "08/31/2023 16:09:38 - INFO - datasets.arrow_dataset - Process #1 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-203d597da0723f71_00001_of_00004.arrow\n",
      "08/31/2023 16:09:38 - INFO - datasets.arrow_dataset - Process #2 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-203d597da0723f71_00002_of_00004.arrow\n",
      "08/31/2023 16:09:38 - INFO - datasets.arrow_dataset - Process #3 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-203d597da0723f71_00003_of_00004.arrow\n",
      "08/31/2023 16:09:38 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-bb1f620ea08b00b9/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-203d597da0723f71_*_of_00004.arrow\n",
      "08/31/2023 16:09:38 - INFO - datasets.arrow_dataset - Concatenating 4 shards\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 36974\n",
      "    })\n",
      "    dev: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 3800\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 3800\n",
      "    })\n",
      "})\n",
      "08/31/2023 16:09:38 - INFO - __main__ - Num train_samples  36974\n",
      "08/31/2023 16:09:38 - INFO - __main__ - training example:\n",
      "08/31/2023 16:09:38 - INFO - __main__ - <s> 问：\n",
      "以下文本包含医疗三元组，请找出并填写：\n",
      "化疗对脉络丛乳头状癌也有效果，术前化疗尚可减少肿瘤体积及血液供应，有助于手术全切。有作者统计12例，5年生存率75%，10年生存率66. 6%。\n",
      "其中的三元组类型是：病理生理，相关（转化），放射治疗，药物治疗，实验室检查，化疗，多发季节，治疗后症状，影像学检查，死亡率，发病部位，并发症，筛查，预后生存率，内窥镜检查，侵及周围组织转移的症状，传播途径，组织学检查，预防，多发地区，相关（症状），临床表现，辅助检查，预后状况，相关（导致），发病年龄，手术治疗，风险评估因素，转移部位，病理分型，同义词，高危因素，发病率，外侵部位，多发群体，发病性别倾向，就诊科室\n",
      "答：\n",
      "具有化疗关系的头尾实体对如下：头实体为脉络丛乳头状癌，尾实体为化疗。头实体为脉络丛乳头状癌，尾实体为术前化疗。\n",
      "具有预后生存率关系的头尾实体对如下：头实体为脉络丛乳头状癌，尾实体为5年生存率75%。头实体为脉络丛乳头状癌，尾实体为10年生存率66. 6%。\n",
      "具有手术治疗关系的头尾实体对如下：头实体为脉络丛乳头状癌，尾实体为手术全切。</s><s>问：\n",
      "帮助患者自动总结问诊的诊疗报告：\n",
      "问诊对话历史：\n",
      "患者：医生你好，我女儿咳嗽，夜里不咳，就是一吃东西就咳得厉害，请问是什么原因？\n",
      "医生：你好\n",
      "患者：你好\n",
      "医生：孩子咳嗽几天了\n",
      "患者：有一个星期了\n",
      "医生：有发烧吗？\n",
      "医生：咳嗽有痰吗？\n",
      "患者：不发烧，有痰\n",
      "医生：去当地公立医院检查过吗？\n",
      "患者：没有，在私人诊所打过针\n",
      "医生：治疗以后效果怎么样？\n",
      "医生：咳嗽见轻吧\n",
      "患者：轻点了\n",
      "医生：但是还是咳嗽，痰比较多是吗\n",
      "08/31/2023 16:09:38 - INFO - __main__ - ？\n",
      "患者：就是吃饭时咳\n",
      "患者：痰不多\n",
      "医生：根据你说的孩子的情况。咳嗽有痰这还是呼吸道的疾病\n",
      "医生：我考虑孩子还是患有上呼吸道感染的。\n",
      "患者：哦，要吃什么药？\n",
      "医生：着凉感染以后都会引起上呼吸道感染的。\n",
      "医生：孩子现在精神好吗？吃饭可以吗？\n",
      "患者：好的\n",
      "医生：那还好根据孩子目前的情况没有发烧精神比较好，吃饭也可以。经过治疗病情也是减轻的，可以继续口服药物缓解一下。\n",
      "医生：可以适当的把药物调整一下。你现在吃的什么药，打的什么针。\n",
      "医生：经过治疗虽然病情减轻，但是还是咳嗽，这是病情还没有完全控制住的。\n",
      "医生：现在吃的什么药物？知道名字吗？\n",
      "患者：小儿止咳糖浆，头孢\n",
      "患者：不打针了\n",
      "医生：吃了几天啦？\n",
      "患者：也有四五天\n",
      "医生：你上边的药物可以继续吃的。\n",
      "患者：哦，\n",
      "医生：可以，再加上氨溴索口服液。和小儿双金清热解毒口服液\n",
      "医生：仔细看说明，按说明书吃。\n",
      "医生：这四种药物一起吃效果还是比较好的\n",
      "医生：加强护理不要着凉的不要吃辛辣的东西，多吃蔬菜和水果。\n",
      "患者：好的，谢谢\n",
      "医生：上呼吸道感染一般的，一周左右会恢复好的。\n",
      "医生：但是孩子小上呼吸道感染很容易引起气管炎和肺炎的。\n",
      "医生：继续口服药物三到四天观察变化。\n",
      "患者：哦，知道了\n",
      "医生：如果咳嗽咳痰不见好转就去当地公立医院小儿内科就诊检查。\n",
      "医生：化验血常规拍胸片看是否有气管炎和肺炎。\n",
      "医生：在采取适当的治疗措施，效果还好。\n",
      "患者：恩\n",
      "医生：如果合并气管炎和肺炎。口服药物效果是不好的，应该静脉输液效果还是比较好的。\n",
      "医生：好的继续口服药物配合，加强护理。观察病情变化如何\n",
      "医生：如果口服药物三至四天。没有咳嗽和咳痰了可以停止药物的\n",
      "医生：口服药三至四天如果没有咳嗽和咳痰，这是病情恢复了，可以停服药物的\n",
      "说明：诊疗报告分为主诉, 现病史, 辅助检查, 既往史, \n",
      "[INFO|modeling_utils.py:2265] 2023-08-31 16:09:38,140 >> Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. Pass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass torch_dtype=torch.float16 to remove this warning.\n",
      "[INFO|modeling_utils.py:2278] 2023-08-31 16:09:38,140 >> The device_map was not initialized.Setting device_map to {'':torch.cuda.current_device()}.If you want to use the model for inference, please set device_map ='auto' \n",
      "[INFO|modeling_utils.py:2575] 2023-08-31 16:09:38,141 >> loading weights file /mnt/workspace/dataroot/models/michaelwzhu/Chinese-LlaMA2-chat-7B-sft-v0.3/pytorch_model.bin.index.json\n",
      "[INFO|modeling_utils.py:1173] 2023-08-31 16:09:38,141 >> Instantiating LlamaForCausalLM model under default dtype torch.float16.\n",
      "[INFO|configuration_utils.py:577] 2023-08-31 16:09:38,141 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"max_length\": 4096,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.30.2\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2690] 2023-08-31 16:09:38,269 >> Detected 8-bit loading: activating 8-bit loading for this model\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [00:09<00:00,  2.27s/it]\n",
      "[INFO|modeling_utils.py:3295] 2023-08-31 16:09:47,571 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:3303] 2023-08-31 16:09:47,571 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at /mnt/workspace/dataroot/models/michaelwzhu/Chinese-LlaMA2-chat-7B-sft-v0.3.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-08-31 16:09:47,574 >> loading configuration file /mnt/workspace/dataroot/models/michaelwzhu/Chinese-LlaMA2-chat-7B-sft-v0.3/generation_config.json\n",
      "[INFO|configuration_utils.py:577] 2023-08-31 16:09:47,575 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"max_length\": 4096,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"temperature\": 0.9,\n",
      "  \"top_p\": 0.6,\n",
      "  \"transformers_version\": \"4.30.2\"\n",
      "}\n",
      "\n",
      "08/31/2023 16:09:47 - INFO - __main__ - Init new peft model\n",
      "['q_proj', 'v_proj', 'k_proj', 'o_proj', 'gate_proj', 'down_proj', 'up_proj']\n",
      "8\n",
      "trainable params: 19,988,480 || all params: 6,905,483,264 || trainable%: 0.28945809056123434\n",
      "[INFO|trainer.py:399] 2023-08-31 16:10:35,468 >> You have loaded a model on multiple GPUs. `is_model_parallel` attribute will be force-set to `True` to avoid any unexpected behavior such as device placement mismatching.\n",
      "[INFO|trainer.py:407] 2023-08-31 16:10:35,468 >> The model is loaded in 8-bit precision. To train this model you need to add additional modules inside the model such as adapters using `peft` library and freeze the model weights. Please check  the examples in https://github.com/huggingface/peft for more details.\n",
      "[INFO|trainer.py:577] 2023-08-31 16:10:35,468 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "**************************************************\n",
      "resume_from_checkpoint:  None\n",
      "**************************************************\n",
      "/opt/conda/lib/python3.8/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "[INFO|trainer.py:1786] 2023-08-31 16:10:35,662 >> ***** Running training *****\n",
      "[INFO|trainer.py:1787] 2023-08-31 16:10:35,662 >>   Num examples = 36,974\n",
      "[INFO|trainer.py:1788] 2023-08-31 16:10:35,662 >>   Num Epochs = 2\n",
      "[INFO|trainer.py:1789] 2023-08-31 16:10:35,662 >>   Instantaneous batch size per device = 1\n",
      "[INFO|trainer.py:1790] 2023-08-31 16:10:35,662 >>   Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "[INFO|trainer.py:1791] 2023-08-31 16:10:35,662 >>   Gradient Accumulation steps = 16\n",
      "[INFO|trainer.py:1792] 2023-08-31 16:10:35,662 >>   Total optimization steps = 2,400\n",
      "[INFO|trainer.py:1793] 2023-08-31 16:10:35,667 >>   Number of trainable parameters = 19,988,480\n",
      "{'loss': 2.5521, 'learning_rate': 4.1666666666666667e-07, 'epoch': 0.0}         \n",
      "{'loss': 5.6814, 'learning_rate': 3.75e-06, 'epoch': 0.0}                       \n",
      "{'loss': 6.4698, 'learning_rate': 7.916666666666667e-06, 'epoch': 0.01}         \n",
      "{'loss': 4.0588, 'learning_rate': 1.2083333333333333e-05, 'epoch': 0.01}        \n",
      "{'loss': 4.6539, 'learning_rate': 1.6250000000000002e-05, 'epoch': 0.02}        \n",
      "{'loss': 3.682, 'learning_rate': 2e-05, 'epoch': 0.02}                          \n",
      "{'loss': 3.4643, 'learning_rate': 2.4166666666666667e-05, 'epoch': 0.03}        \n",
      "{'loss': 3.5506, 'learning_rate': 2.8333333333333335e-05, 'epoch': 0.03}        \n",
      "{'loss': 4.4163, 'learning_rate': 3.2500000000000004e-05, 'epoch': 0.03}        \n",
      "{'loss': 2.6665, 'learning_rate': 3.6666666666666666e-05, 'epoch': 0.04}        \n",
      "{'loss': 2.8273, 'learning_rate': 4.0833333333333334e-05, 'epoch': 0.04}        \n",
      "  4%|█▌                                    | 100/2400 [20:48<7:56:16, 12.42s/it][INFO|trainer.py:2926] 2023-08-31 16:31:24,547 >> Saving model checkpoint to ./output/promptcblue-llama-7b-pt-v0/checkpoint-100\n",
      "[INFO|tokenization_utils_base.py:2194] 2023-08-31 16:31:24,650 >> tokenizer config file saved in ./output/promptcblue-llama-7b-pt-v0/checkpoint-100/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2201] 2023-08-31 16:31:24,650 >> Special tokens file saved in ./output/promptcblue-llama-7b-pt-v0/checkpoint-100/special_tokens_map.json\n",
      "{'loss': 3.0732, 'learning_rate': 4.5e-05, 'epoch': 0.05}                       \n",
      "{'loss': 3.3028, 'learning_rate': 4.9166666666666665e-05, 'epoch': 0.05}        \n",
      "{'loss': 3.2061, 'learning_rate': 4.999848114735858e-05, 'epoch': 0.06}         \n",
      "{'loss': 2.0334, 'learning_rate': 4.9992311124800875e-05, 'epoch': 0.06}        \n",
      "{'loss': 2.691, 'learning_rate': 4.9981396174548355e-05, 'epoch': 0.06}         \n",
      "{'loss': 1.7895, 'learning_rate': 4.996573836886435e-05, 'epoch': 0.07}         \n",
      "{'loss': 2.4412, 'learning_rate': 4.994534068046937e-05, 'epoch': 0.07}         \n",
      "{'loss': 2.4356, 'learning_rate': 4.99229333433282e-05, 'epoch': 0.08}          \n",
      "{'loss': 1.9573, 'learning_rate': 4.989354129000368e-05, 'epoch': 0.08}         \n",
      "{'loss': 2.3966, 'learning_rate': 4.98594230609806e-05, 'epoch': 0.09}          \n",
      "  8%|███▏                                  | 200/2400 [41:39<7:36:20, 12.45s/it][INFO|trainer.py:2926] 2023-08-31 16:52:14,950 >> Saving model checkpoint to ./output/promptcblue-llama-7b-pt-v0/checkpoint-200\n",
      "[INFO|tokenization_utils_base.py:2194] 2023-08-31 16:52:15,049 >> tokenizer config file saved in ./output/promptcblue-llama-7b-pt-v0/checkpoint-200/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2201] 2023-08-31 16:52:15,049 >> Special tokens file saved in ./output/promptcblue-llama-7b-pt-v0/checkpoint-200/special_tokens_map.json\n",
      "{'loss': 2.7825, 'learning_rate': 4.982058513379235e-05, 'epoch': 0.09}         \n",
      "{'loss': 1.473, 'learning_rate': 4.9777034882032966e-05, 'epoch': 0.1}          \n",
      "{'loss': 1.6047, 'learning_rate': 4.9728780573957226e-05, 'epoch': 0.1}         \n",
      "{'loss': 2.1108, 'learning_rate': 4.967583137091085e-05, 'epoch': 0.1}          \n",
      "{'loss': 1.3295, 'learning_rate': 4.9618197325591195e-05, 'epoch': 0.11}        \n",
      "{'loss': 1.8815, 'learning_rate': 4.95558893801387e-05, 'epoch': 0.11}          \n",
      "{'loss': 1.6089, 'learning_rate': 4.948891936405941e-05, 'epoch': 0.12}         \n",
      "{'loss': 2.8919, 'learning_rate': 4.9417299991979125e-05, 'epoch': 0.12}        \n",
      "{'loss': 1.7505, 'learning_rate': 4.934104486122947e-05, 'epoch': 0.13}         \n",
      "{'loss': 1.7807, 'learning_rate': 4.9260168449266335e-05, 'epoch': 0.13}        \n",
      " 12%|████▌                               | 300/2400 [1:02:30<7:20:13, 12.58s/it][INFO|trainer.py:2926] 2023-08-31 17:13:06,531 >> Saving model checkpoint to ./output/promptcblue-llama-7b-pt-v0/checkpoint-300\n",
      "[INFO|tokenization_utils_base.py:2194] 2023-08-31 17:13:06,634 >> tokenizer config file saved in ./output/promptcblue-llama-7b-pt-v0/checkpoint-300/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2201] 2023-08-31 17:13:06,634 >> Special tokens file saved in ./output/promptcblue-llama-7b-pt-v0/checkpoint-300/special_tokens_map.json\n",
      "{'loss': 2.834, 'learning_rate': 4.9174686110921245e-05, 'epoch': 0.13}         \n",
      "{'loss': 2.4479, 'learning_rate': 4.908461407548618e-05, 'epoch': 0.14}         \n",
      "{'loss': 1.9683, 'learning_rate': 4.8989969443632366e-05, 'epoch': 0.14}        \n",
      "{'loss': 1.4598, 'learning_rate': 4.889077018416359e-05, 'epoch': 0.15}         \n",
      "{'loss': 2.4734, 'learning_rate': 4.878703513060474e-05, 'epoch': 0.15}         \n",
      "{'loss': 1.4505, 'learning_rate': 4.8678783977626155e-05, 'epoch': 0.16}        \n",
      "{'loss': 3.2044, 'learning_rate': 4.856603727730447e-05, 'epoch': 0.16}         \n",
      "{'loss': 1.9918, 'learning_rate': 4.8448816435220714e-05, 'epoch': 0.16}        \n",
      "{'loss': 4.0932, 'learning_rate': 4.832714370639633e-05, 'epoch': 0.17}         \n",
      "{'loss': 1.9295, 'learning_rate': 4.8201042191067956e-05, 'epoch': 0.17}        \n",
      " 17%|██████                              | 400/2400 [1:23:23<6:59:11, 12.58s/it][INFO|trainer.py:2926] 2023-08-31 17:33:58,688 >> Saving model checkpoint to ./output/promptcblue-llama-7b-pt-v0/checkpoint-400\n",
      "[INFO|tokenization_utils_base.py:2194] 2023-08-31 17:33:58,792 >> tokenizer config file saved in ./output/promptcblue-llama-7b-pt-v0/checkpoint-400/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2201] 2023-08-31 17:33:58,792 >> Special tokens file saved in ./output/promptcblue-llama-7b-pt-v0/checkpoint-400/special_tokens_map.json\n",
      "{'loss': 1.568, 'learning_rate': 4.8070535830301664e-05, 'epoch': 0.18}         \n",
      "{'loss': 2.005, 'learning_rate': 4.793564940144769e-05, 'epoch': 0.18}          \n",
      "{'loss': 1.4293, 'learning_rate': 4.7796408513436255e-05, 'epoch': 0.19}        \n",
      "{'loss': 2.0954, 'learning_rate': 4.765283960191561e-05, 'epoch': 0.19}         \n",
      "{'loss': 3.4633, 'learning_rate': 4.750496992423307e-05, 'epoch': 0.19}         \n",
      "{'loss': 1.2828, 'learning_rate': 4.735282755426004e-05, 'epoch': 0.2}          \n",
      "{'loss': 1.7628, 'learning_rate': 4.719644137706205e-05, 'epoch': 0.2}          \n",
      "{'loss': 1.6152, 'learning_rate': 4.703584108341481e-05, 'epoch': 0.21}         \n",
      "{'loss': 1.0042, 'learning_rate': 4.6871057164167143e-05, 'epoch': 0.21}        \n",
      "{'loss': 1.6946, 'learning_rate': 4.6702120904452256e-05, 'epoch': 0.22}        \n",
      " 21%|███████▌                            | 500/2400 [1:44:15<6:38:13, 12.58s/it][INFO|trainer.py:2926] 2023-08-31 17:54:51,523 >> Saving model checkpoint to ./output/promptcblue-llama-7b-pt-v0/checkpoint-500\n",
      "[INFO|tokenization_utils_base.py:2194] 2023-08-31 17:54:51,627 >> tokenizer config file saved in ./output/promptcblue-llama-7b-pt-v0/checkpoint-500/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2201] 2023-08-31 17:54:51,627 >> Special tokens file saved in ./output/promptcblue-llama-7b-pt-v0/checkpoint-500/special_tokens_map.json\n",
      "{'loss': 1.6329, 'learning_rate': 4.652906437774799e-05, 'epoch': 0.22}         \n",
      "{'loss': 1.1193, 'learning_rate': 4.635192043978756e-05, 'epoch': 0.23}         \n",
      "{'loss': 1.0166, 'learning_rate': 4.6189023939709096e-05, 'epoch': 0.23}        \n",
      "{'loss': 1.4671, 'learning_rate': 4.600420721207053e-05, 'epoch': 0.23}         \n",
      "{'loss': 1.7173, 'learning_rate': 4.581540272019476e-05, 'epoch': 0.24}         \n",
      "{'loss': 2.2066, 'learning_rate': 4.5622646309652794e-05, 'epoch': 0.24}        \n",
      "{'loss': 1.6986, 'learning_rate': 4.542597457630909e-05, 'epoch': 0.25}         \n",
      "{'loss': 1.2986, 'learning_rate': 4.522542485937369e-05, 'epoch': 0.25}         \n",
      "{'loss': 1.193, 'learning_rate': 4.502103523431312e-05, 'epoch': 0.26}          \n",
      "{'loss': 1.7755, 'learning_rate': 4.481284450562163e-05, 'epoch': 0.26}         \n",
      " 25%|█████████                           | 600/2400 [2:05:08<6:14:39, 12.49s/it][INFO|trainer.py:2926] 2023-08-31 18:15:44,481 >> Saving model checkpoint to ./output/promptcblue-llama-7b-pt-v0/checkpoint-600\n",
      "[INFO|tokenization_utils_base.py:2194] 2023-08-31 18:15:44,584 >> tokenizer config file saved in ./output/promptcblue-llama-7b-pt-v0/checkpoint-600/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2201] 2023-08-31 18:15:44,584 >> Special tokens file saved in ./output/promptcblue-llama-7b-pt-v0/checkpoint-600/special_tokens_map.json\n",
      "{'loss': 1.9256, 'learning_rate': 4.460089219945382e-05, 'epoch': 0.26}         \n",
      "{'loss': 2.2601, 'learning_rate': 4.438521855612054e-05, 'epoch': 0.27}         \n",
      "{'loss': 1.4167, 'learning_rate': 4.41658645224489e-05, 'epoch': 0.27}          \n",
      "{'loss': 2.4121, 'learning_rate': 4.3942871744008374e-05, 'epoch': 0.28}        \n",
      "{'loss': 1.6086, 'learning_rate': 4.371628255720415e-05, 'epoch': 0.28}         \n",
      "{'loss': 1.538, 'learning_rate': 4.3486139981239304e-05, 'epoch': 0.29}         \n",
      "{'loss': 1.9748, 'learning_rate': 4.325248770994741e-05, 'epoch': 0.29}         \n",
      "{'loss': 2.0964, 'learning_rate': 4.301537010349696e-05, 'epoch': 0.29}         \n",
      "{'loss': 1.2152, 'learning_rate': 4.277483217996941e-05, 'epoch': 0.3}          \n",
      "{'loss': 2.674, 'learning_rate': 4.2530919606812216e-05, 'epoch': 0.3}          \n",
      " 29%|██████████▌                         | 700/2400 [2:25:57<5:54:07, 12.50s/it][INFO|trainer.py:2926] 2023-08-31 18:36:33,567 >> Saving model checkpoint to ./output/promptcblue-llama-7b-pt-v0/checkpoint-700\n",
      "[INFO|tokenization_utils_base.py:2194] 2023-08-31 18:36:33,674 >> tokenizer config file saved in ./output/promptcblue-llama-7b-pt-v0/checkpoint-700/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2201] 2023-08-31 18:36:33,674 >> Special tokens file saved in ./output/promptcblue-llama-7b-pt-v0/checkpoint-700/special_tokens_map.json\n",
      "{'loss': 2.2806, 'learning_rate': 4.2283678692168615e-05, 'epoch': 0.31}        \n",
      "{'loss': 1.0896, 'learning_rate': 4.203315637608578e-05, 'epoch': 0.31}         \n",
      "{'loss': 1.5469, 'learning_rate': 4.177940022160299e-05, 'epoch': 0.32}         \n",
      "{'loss': 2.4407, 'learning_rate': 4.152245840572153e-05, 'epoch': 0.32}         \n",
      "{'loss': 1.7392, 'learning_rate': 4.126237971025803e-05, 'epoch': 0.32}         \n",
      "{'loss': 1.6823, 'learning_rate': 4.099921351258292e-05, 'epoch': 0.33}         \n",
      "{'loss': 1.6622, 'learning_rate': 4.073300977624594e-05, 'epoch': 0.33}         \n",
      "{'loss': 1.7046, 'learning_rate': 4.046381904149024e-05, 'epoch': 0.34}         \n",
      "{'loss': 1.4654, 'learning_rate': 4.019169241565703e-05, 'epoch': 0.34}         \n",
      "{'loss': 2.7048, 'learning_rate': 3.991668156348261e-05, 'epoch': 0.35}         \n",
      " 33%|████████████                        | 800/2400 [2:46:48<5:33:38, 12.51s/it][INFO|trainer.py:2926] 2023-08-31 18:57:23,933 >> Saving model checkpoint to ./output/promptcblue-llama-7b-pt-v0/checkpoint-800\n",
      "[INFO|tokenization_utils_base.py:2194] 2023-08-31 18:57:24,036 >> tokenizer config file saved in ./output/promptcblue-llama-7b-pt-v0/checkpoint-800/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2201] 2023-08-31 18:57:24,036 >> Special tokens file saved in ./output/promptcblue-llama-7b-pt-v0/checkpoint-800/special_tokens_map.json\n",
      "{'loss': 2.0628, 'learning_rate': 3.9638838697289484e-05, 'epoch': 0.35}        \n",
      "{'loss': 2.9284, 'learning_rate': 3.935821656707359e-05, 'epoch': 0.35}         \n",
      "{'loss': 1.9673, 'learning_rate': 3.9074868450489465e-05, 'epoch': 0.36}        \n",
      "{'loss': 1.0606, 'learning_rate': 3.878884814273509e-05, 'epoch': 0.36}         \n",
      "{'loss': 2.0409, 'learning_rate': 3.850020994633868e-05, 'epoch': 0.37}         \n",
      "{'loss': 1.5474, 'learning_rate': 3.8209008660848974e-05, 'epoch': 0.37}        \n",
      "{'loss': 1.6097, 'learning_rate': 3.7915299572431286e-05, 'epoch': 0.38}        \n",
      "{'loss': 1.7742, 'learning_rate': 3.76191384433711e-05, 'epoch': 0.38}          \n",
      "{'loss': 2.2322, 'learning_rate': 3.732058150148729e-05, 'epoch': 0.39}         \n",
      "{'loss': 1.1758, 'learning_rate': 3.7019685429456986e-05, 'epoch': 0.39}        \n",
      " 38%|█████████████▌                      | 900/2400 [3:07:38<5:12:22, 12.50s/it][INFO|trainer.py:2926] 2023-08-31 19:18:14,237 >> Saving model checkpoint to ./output/promptcblue-llama-7b-pt-v0/checkpoint-900\n",
      "[INFO|tokenization_utils_base.py:2194] 2023-08-31 19:18:14,342 >> tokenizer config file saved in ./output/promptcblue-llama-7b-pt-v0/checkpoint-900/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2201] 2023-08-31 19:18:14,343 >> Special tokens file saved in ./output/promptcblue-llama-7b-pt-v0/checkpoint-900/special_tokens_map.json\n",
      "{'loss': 1.1027, 'learning_rate': 3.671650735405404e-05, 'epoch': 0.39}         \n",
      "{'loss': 1.3272, 'learning_rate': 3.6411104835303166e-05, 'epoch': 0.4}         \n",
      "{'loss': 1.4595, 'learning_rate': 3.610353585555191e-05, 'epoch': 0.4}          \n",
      "{'loss': 2.3427, 'learning_rate': 3.579385880846232e-05, 'epoch': 0.41}         \n",
      "{'loss': 1.3627, 'learning_rate': 3.548213248792467e-05, 'epoch': 0.41}         \n",
      "{'loss': 1.3945, 'learning_rate': 3.516841607689501e-05, 'epoch': 0.42}         \n",
      "{'loss': 1.1403, 'learning_rate': 3.485276913615905e-05, 'epoch': 0.42}         \n",
      "{'loss': 2.7054, 'learning_rate': 3.453525159302415e-05, 'epoch': 0.42}         \n",
      "{'loss': 1.4126, 'learning_rate': 3.4215923729941866e-05, 'epoch': 0.43}        \n",
      "{'loss': 1.2817, 'learning_rate': 3.389484617306292e-05, 'epoch': 0.43}         \n",
      " 42%|██████████████▌                    | 1000/2400 [3:28:27<4:52:24, 12.53s/it][INFO|trainer.py:2926] 2023-08-31 19:39:02,901 >> Saving model checkpoint to ./output/promptcblue-llama-7b-pt-v0/checkpoint-1000\n",
      "[INFO|tokenization_utils_base.py:2194] 2023-08-31 19:39:03,002 >> tokenizer config file saved in ./output/promptcblue-llama-7b-pt-v0/checkpoint-1000/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2201] 2023-08-31 19:39:03,002 >> Special tokens file saved in ./output/promptcblue-llama-7b-pt-v0/checkpoint-1000/special_tokens_map.json\n",
      "{'loss': 2.9058, 'learning_rate': 3.357207988072701e-05, 'epoch': 0.44}         \n",
      "{'loss': 1.639, 'learning_rate': 3.3247686131889574e-05, 'epoch': 0.44}         \n",
      "{'loss': 1.5787, 'learning_rate': 3.2921726514487614e-05, 'epoch': 0.45}        \n",
      "{'loss': 2.6119, 'learning_rate': 3.2594262913746865e-05, 'epoch': 0.45}        \n",
      "{'loss': 2.2649, 'learning_rate': 3.22653575004326e-05, 'epoch': 0.45}          \n",
      "{'loss': 1.0033, 'learning_rate': 3.1935072719046115e-05, 'epoch': 0.46}        \n",
      "{'loss': 1.5058, 'learning_rate': 3.1603471275969335e-05, 'epoch': 0.46}        \n",
      "{'loss': 2.9176, 'learning_rate': 3.127061612755961e-05, 'epoch': 0.47}         \n",
      "{'loss': 2.2854, 'learning_rate': 3.093657046819722e-05, 'epoch': 0.47}         \n",
      "{'loss': 1.7579, 'learning_rate': 3.06013977182874e-05, 'epoch': 0.48}          \n",
      " 46%|████████████████                   | 1100/2400 [3:49:16<4:31:57, 12.55s/it][INFO|trainer.py:2926] 2023-08-31 19:59:52,581 >> Saving model checkpoint to ./output/promptcblue-llama-7b-pt-v0/checkpoint-1100\n",
      "[INFO|tokenization_utils_base.py:2194] 2023-08-31 19:59:52,687 >> tokenizer config file saved in ./output/promptcblue-llama-7b-pt-v0/checkpoint-1100/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2201] 2023-08-31 19:59:52,687 >> Special tokens file saved in ./output/promptcblue-llama-7b-pt-v0/checkpoint-1100/special_tokens_map.json\n",
      "{'loss': 1.5668, 'learning_rate': 3.0265161512219796e-05, 'epoch': 0.48}        \n",
      "{'loss': 1.7538, 'learning_rate': 2.9927925686287006e-05, 'epoch': 0.48}        \n",
      "{'loss': 2.6218, 'learning_rate': 2.9589754266565002e-05, 'epoch': 0.49}        \n",
      "{'loss': 2.1338, 'learning_rate': 2.925071145675733e-05, 'epoch': 0.49}         \n",
      "{'loss': 2.0505, 'learning_rate': 2.8910861626005776e-05, 'epoch': 0.5}         \n",
      "{'loss': 1.828, 'learning_rate': 2.8570269296669466e-05, 'epoch': 0.5}          \n",
      "{'loss': 1.5493, 'learning_rate': 2.8228999132074985e-05, 'epoch': 0.51}        \n",
      "{'loss': 1.151, 'learning_rate': 2.788711592423966e-05, 'epoch': 0.51}          \n",
      "{'loss': 3.7369, 'learning_rate': 2.754468458157043e-05, 'epoch': 0.51}         \n",
      "{'loss': 1.9932, 'learning_rate': 2.720177011654067e-05, 'epoch': 0.52}         \n",
      " 50%|█████████████████▌                 | 1200/2400 [4:10:08<4:10:42, 12.54s/it][INFO|trainer.py:2926] 2023-08-31 20:20:44,570 >> Saving model checkpoint to ./output/promptcblue-llama-7b-pt-v0/checkpoint-1200\n",
      "[INFO|tokenization_utils_base.py:2194] 2023-08-31 20:20:44,670 >> tokenizer config file saved in ./output/promptcblue-llama-7b-pt-v0/checkpoint-1200/tokenizer_config.json\n",
      "[INFO|tokenization_utils_base.py:2201] 2023-08-31 20:20:44,670 >> Special tokens file saved in ./output/promptcblue-llama-7b-pt-v0/checkpoint-1200/special_tokens_map.json\n",
      "{'loss': 2.0611, 'learning_rate': 2.6858437633347194e-05, 'epoch': 0.52}        \n",
      " 51%|█████████████████▋                 | 1215/2400 [4:13:15<4:03:46, 12.34s/it]"
     ]
    }
   ],
   "source": [
    "!sh src/ft_llama_lora/run_train.sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0b6fb3a-e43a-4df3-b6da-6d75e3dac2a0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T08:03:52.125143Z",
     "iopub.status.busy": "2023-08-31T08:03:52.124660Z",
     "iopub.status.idle": "2023-08-31T08:03:56.325188Z",
     "shell.execute_reply": "2023-08-31T08:03:56.324483Z",
     "shell.execute_reply.started": "2023-08-31T08:03:52.125112Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://mirrors.aliyun.com/pypi/simple\n",
      "Collecting peft==0.4.0\n",
      "  Downloading https://mirrors.aliyun.com/pypi/packages/88/a0/6e1c23293a922a9c9e9bd8d56a60cd78ecf531fdabe45ac975e142bfbe86/peft-0.4.0-py3-none-any.whl (72 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m484.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.8/site-packages (from peft==0.4.0) (1.22.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.8/site-packages (from peft==0.4.0) (23.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.8/site-packages (from peft==0.4.0) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.8/site-packages (from peft==0.4.0) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.13.0 in /opt/conda/lib/python3.8/site-packages (from peft==0.4.0) (2.0.1+cu117)\n",
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.8/site-packages (from peft==0.4.0) (4.30.2)\n",
      "Requirement already satisfied: accelerate in /opt/conda/lib/python3.8/site-packages (from peft==0.4.0) (0.21.0)\n",
      "Requirement already satisfied: safetensors in /opt/conda/lib/python3.8/site-packages (from peft==0.4.0) (0.3.1)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.4.0) (3.12.2)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.4.0) (4.7.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.4.0) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.4.0) (2.8.4)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.4.0) (3.1.2)\n",
      "Requirement already satisfied: triton==2.0.0 in /opt/conda/lib/python3.8/site-packages (from torch>=1.13.0->peft==0.4.0) (2.0.0)\n",
      "Requirement already satisfied: cmake in /opt/conda/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.13.0->peft==0.4.0) (3.27.0)\n",
      "Requirement already satisfied: lit in /opt/conda/lib/python3.8/site-packages (from triton==2.0.0->torch>=1.13.0->peft==0.4.0) (16.0.6)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /opt/conda/lib/python3.8/site-packages (from transformers->peft==0.4.0) (0.16.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.8/site-packages (from transformers->peft==0.4.0) (2023.6.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.8/site-packages (from transformers->peft==0.4.0) (2.29.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.8/site-packages (from transformers->peft==0.4.0) (0.13.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.8/site-packages (from transformers->peft==0.4.0) (4.65.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers->peft==0.4.0) (2023.6.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.8/site-packages (from jinja2->torch>=1.13.0->peft==0.4.0) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->peft==0.4.0) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->peft==0.4.0) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->peft==0.4.0) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests->transformers->peft==0.4.0) (2023.5.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.8/site-packages (from sympy->torch>=1.13.0->peft==0.4.0) (1.3.0)\n",
      "\u001b[33mDEPRECATION: pytorch-lightning 1.7.7 has a non-standard dependency specifier torch>=1.9.*. pip 23.3 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of pytorch-lightning or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\u001b[0m\u001b[33m\n",
      "\u001b[0mInstalling collected packages: peft\n",
      "Successfully installed peft-0.4.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install peft==0.4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6d8469-8710-4d7c-ba7e-29d9842e9de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 仅保存lora参数, peftmodel.save_pretrained(\"output_dir\")\n",
    "# 加载多个lora模块：https://blog.csdn.net/BIT_666/article/details/132065177"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d62ec2fb-a27c-4b33-a902-a65bdae19d38",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T02:09:16.545640Z",
     "iopub.status.busy": "2023-09-01T02:09:16.545076Z",
     "iopub.status.idle": "2023-09-01T02:11:40.678832Z",
     "shell.execute_reply": "2023-09-01T02:11:40.678203Z",
     "shell.execute_reply.started": "2023-09-01T02:09:16.545618Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-01 10:09:22,409] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "2023-09-01 10:09:23.123730: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "09/01/2023 10:09:25 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "[INFO|configuration_utils.py:667] 2023-09-01 10:09:25,203 >> loading configuration file /mnt/workspace/dataroot/models/michaelwzhu/Chinese-LlaMA2-chat-7B-sft-v0.3/config.json\n",
      "[INFO|configuration_utils.py:725] 2023-09-01 10:09:25,203 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"/mnt/workspace/dataroot/models/michaelwzhu/Chinese-LlaMA2-chat-7B-sft-v0.3\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_length\": 4096,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.30.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 49954\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1821] 2023-09-01 10:09:25,204 >> loading file tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:1821] 2023-09-01 10:09:25,204 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:1821] 2023-09-01 10:09:25,204 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1821] 2023-09-01 10:09:25,204 >> loading file tokenizer_config.json\n",
      "09/01/2023 10:09:26 - INFO - datasets.builder - Using custom data configuration default-595c04e6da153d9d\n",
      "09/01/2023 10:09:26 - INFO - datasets.info - Loading Dataset Infos from /opt/conda/lib/python3.8/site-packages/datasets/packaged_modules/json\n",
      "09/01/2023 10:09:26 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
      "09/01/2023 10:09:26 - INFO - datasets.info - Loading Dataset info from /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4\n",
      "09/01/2023 10:09:26 - WARNING - datasets.builder - Found cached dataset json (/mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "09/01/2023 10:09:26 - INFO - datasets.info - Loading Dataset info from /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4\n",
      "100%|████████████████████████████████████████████| 3/3 [00:00<00:00, 218.23it/s]\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Process #0 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-2df00f26b3af8cbc_00000_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Process #1 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-2df00f26b3af8cbc_00001_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Process #2 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-2df00f26b3af8cbc_00002_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Process #3 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-2df00f26b3af8cbc_00003_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Spawning 4 processes\n",
      "Running tokenizer on dataset (num_proc=4):   0%|  | 0/20 [00:00<?, ? examples/s]09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-2df00f26b3af8cbc_00001_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-2df00f26b3af8cbc_00002_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-2df00f26b3af8cbc_00000_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-2df00f26b3af8cbc_00003_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Concatenating 4 shards    \n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Process #0 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-f4142dd6b499af7b_00000_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Process #1 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-f4142dd6b499af7b_00001_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Process #2 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-f4142dd6b499af7b_00002_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Process #3 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-f4142dd6b499af7b_00003_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Spawning 4 processes\n",
      "Running tokenizer on dataset (num_proc=4):   0%|  | 0/20 [00:00<?, ? examples/s]09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-f4142dd6b499af7b_00000_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-f4142dd6b499af7b_00003_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-f4142dd6b499af7b_00001_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-f4142dd6b499af7b_00002_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Concatenating 4 shards    \n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Process #0 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-470a95906b976566_00000_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Process #1 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-470a95906b976566_00001_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Process #2 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-470a95906b976566_00002_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Process #3 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-470a95906b976566_00003_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Spawning 4 processes\n",
      "Running tokenizer on dataset (num_proc=4):   0%|  | 0/20 [00:00<?, ? examples/s]09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-470a95906b976566_00000_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-470a95906b976566_00003_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-470a95906b976566_00001_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-470a95906b976566_00002_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Concatenating 4 shards    \n",
      "tokenized_dataset:  DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 20\n",
      "    })\n",
      "    dev: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 20\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 20\n",
      "    })\n",
      "})\n",
      "[1, 29871, 31658, 30383, 13, 32237, 31138, 32380, 36655, 30214, 39313, 34339, 36655, 30275, 34534, 30210, 33942, 37110, 30214, 31666, 37887, 38920, 31149, 39990, 30952, 30383, 13, 36655, 32342, 30383, 13, 32822, 30383, 32593, 41049, 31639, 32269, 43434, 43095, 30210, 32027, 30882, 13, 32822, 30383, 38020, 33096, 30806, 36021, 32822, 31999, 38020, 32764, 32066, 32161, 32058, 30882, 13, 34339, 36655, 30383, 13, 33062, 30383, 31238, 32292, 30850, 32980, 33673, 34982, 43095, 13, 30682, 31333, 39990, 30952, 41133, 30383, 32009, 42147, 31751, 33942, 30214, 42147, 31751, 33942, 30214, 32395, 32237, 35230, 30333, 32932, 35358, 32262, 42147, 31751, 33942, 13, 33091, 30383, 13, 34339, 36655, 32204, 33942, 33858, 39990, 30952, 33933, 30573, 30383, 13, 43095, 30383, 32009, 42147, 31751, 33942, 2]\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 34339, 36655, 32204, 33942, 33858, 39990, 30952, 33933, 30573, 30383, 13, 43095, 30383, 32009, 42147, 31751, 33942, 2]\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Process #0 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-b096e7f4aab099e0_00000_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Process #1 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-b096e7f4aab099e0_00001_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Process #2 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-b096e7f4aab099e0_00002_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Process #3 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-b096e7f4aab099e0_00003_of_00004.arrow\n",
      "09/01/2023 10:09:26 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-b096e7f4aab099e0_*_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Concatenating 4 shards\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Process #0 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-4b34986914f2401f_00000_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Process #1 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-4b34986914f2401f_00001_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Process #2 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-4b34986914f2401f_00002_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Process #3 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-4b34986914f2401f_00003_of_00004.arrow\n",
      "09/01/2023 10:09:26 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-4b34986914f2401f_*_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Concatenating 4 shards\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Process #0 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-4a2f5cded25be188_00000_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Process #1 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-4a2f5cded25be188_00001_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Process #2 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-4a2f5cded25be188_00002_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Process #3 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-4a2f5cded25be188_00003_of_00004.arrow\n",
      "09/01/2023 10:09:26 - WARNING - datasets.arrow_dataset - Loading cached processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-595c04e6da153d9d/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-4a2f5cded25be188_*_of_00004.arrow\n",
      "09/01/2023 10:09:26 - INFO - datasets.arrow_dataset - Concatenating 4 shards\n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 11\n",
      "    })\n",
      "    dev: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 11\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 11\n",
      "    })\n",
      "})\n",
      "09/01/2023 10:09:26 - INFO - __main__ - Num eval_samples  11\n",
      "09/01/2023 10:09:26 - INFO - __main__ - training example:\n",
      "09/01/2023 10:09:26 - INFO - __main__ - <s> 问：\n",
      "请问是什么意图类型？\n",
      "癫痫怎么治愈\n",
      "搜索意图选项：治疗方案，病情诊断，指标解读，病因分析，注意事项，功效作用，医疗费用\n",
      "答：\n",
      "治疗方案</s><s>问：\n",
      "请根据下述医疗指南文本，提取诊疗决策树：\n",
      "AVNRT患者@合并低血压者可应用升压药物（如去氧肾上腺素、甲氧明或间羟胺），通过反射性兴奋迷走神经终止心动过速。但老年患者、高血压、急性心肌梗死患者等禁用升压药物。\n",
      "说明：(1)我们将诊疗决策树定义为由条件节点和决策节点组成的二叉树，旨在通过简洁的结构化信息表达指南文本，既要求将文本中的核心实体和关系挖掘出来，也需要将这些信息进行串联，形成一个完整的决策流程；(2)在诊疗决策二叉树中，非叶子节点是条件节点，叶子节点是决策节点。对于条件节点，当条件判断结果为“是”时，将转到左侧子节点进行下一个判断或决策，当条件判断结果为“否”时，将转到右侧子节点进行下一个判断或决策。(3)每个节点输出为一个dict，包含三个字段：(3a)\"role\"，即节点类型，表示节点是一个条件节点(\"C\")或者是决策节点(\"D\")；(3b)\"triples\"，即三元组列表，用来描述诊疗知识或者临床信息的三元组，即条件/决策节点的内容，三元组关系共定义了6类：\"临床表现\", \"治疗药物\", \"用法用量\", \"治疗方案\", \"禁用药物\", \"基本情况\"；(3c)\"logical_rel\"，表示多个三元组之间的逻辑关系（取值为and, or, null，当只有三元组的个数<=1时逻辑关系为 null）。(4)整个诊疗决策树以广度优先策略排列为一个列表。\n",
      "答：\n",
      "根据给定的指南文本抽取的诊疗决策树如下：\n",
      "节点0：role=C；logical_rel=null；triples=[[\"AVNRT患者\", \"临床表现\", \"低血压\"]]\n",
      "节点1：role=D；logical_rel=or；triples=[[\"AVNRT患者\", \"治疗药物\", \"升\n",
      "[INFO|modeling_utils.py:2265] 2023-09-01 10:09:26,738 >> Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. Pass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass torch_dtype=torch.float16 to remove this warning.\n",
      "[INFO|modeling_utils.py:2278] 2023-09-01 10:09:26,738 >> The device_map was not initialized.Setting device_map to {'':torch.cuda.current_device()}.If you want to use the model for inference, please set device_map ='auto' \n",
      "[INFO|modeling_utils.py:2575] 2023-09-01 10:09:26,738 >> loading weights file /mnt/workspace/dataroot/models/michaelwzhu/Chinese-LlaMA2-chat-7B-sft-v0.3/pytorch_model.bin.index.json\n",
      "[INFO|modeling_utils.py:1173] 2023-09-01 10:09:26,739 >> Instantiating LlamaForCausalLM model under default dtype torch.float16.\n",
      "[INFO|configuration_utils.py:577] 2023-09-01 10:09:26,740 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"max_length\": 4096,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.30.2\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2690] 2023-09-01 10:09:26,911 >> Detected 8-bit loading: activating 8-bit loading for this model\n",
      "Loading checkpoint shards: 100%|██████████████████| 4/4 [01:20<00:00, 20.07s/it]\n",
      "[INFO|modeling_utils.py:3295] 2023-09-01 10:10:47,524 >> All model checkpoint weights were used when initializing LlamaForCausalLM.\n",
      "\n",
      "[INFO|modeling_utils.py:3303] 2023-09-01 10:10:47,524 >> All the weights of LlamaForCausalLM were initialized from the model checkpoint at /mnt/workspace/dataroot/models/michaelwzhu/Chinese-LlaMA2-chat-7B-sft-v0.3.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use LlamaForCausalLM for predictions without further training.\n",
      "[INFO|configuration_utils.py:537] 2023-09-01 10:10:47,528 >> loading configuration file /mnt/workspace/dataroot/models/michaelwzhu/Chinese-LlaMA2-chat-7B-sft-v0.3/generation_config.json\n",
      "[INFO|configuration_utils.py:577] 2023-09-01 10:10:47,528 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"max_length\": 4096,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"temperature\": 0.9,\n",
      "  \"top_p\": 0.6,\n",
      "  \"transformers_version\": \"4.30.2\"\n",
      "}\n",
      "\n",
      "09/01/2023 10:10:47 - INFO - __main__ - Peft from pre-trained model\n",
      "trainable params: 0 || all params: 6,905,483,264 || trainable%: 0.0\n",
      "[INFO|trainer.py:399] 2023-09-01 10:11:35,026 >> You have loaded a model on multiple GPUs. `is_model_parallel` attribute will be force-set to `True` to avoid any unexpected behavior such as device placement mismatching.\n",
      "[INFO|trainer.py:407] 2023-09-01 10:11:35,026 >> The model is loaded in 8-bit precision. To train this model you need to add additional modules inside the model such as adapters using `peft` library and freeze the model weights. Please check  the examples in https://github.com/huggingface/peft for more details.\n",
      "[INFO|trainer.py:577] 2023-09-01 10:11:35,026 >> max_steps is given, it will override any value given in num_train_epochs\n",
      "09/01/2023 10:11:35 - INFO - __main__ - *** Evaluate ***\n",
      "[INFO|trainer.py:3200] 2023-09-01 10:11:35,029 >> ***** Running Evaluation *****\n",
      "[INFO|trainer.py:3202] 2023-09-01 10:11:35,029 >>   Num examples = 11\n",
      "[INFO|trainer.py:3205] 2023-09-01 10:11:35,029 >>   Batch size = 1\n",
      "100%|███████████████████████████████████████████| 11/11 [00:02<00:00,  4.34it/s]\n",
      "***** eval metrics *****\n",
      "  eval_loss               =     0.5276\n",
      "  eval_runtime            = 0:00:04.45\n",
      "  eval_samples            =         11\n",
      "  eval_samples_per_second =      2.468\n",
      "  eval_steps_per_second   =      2.468\n",
      "  perplexity              =     1.6949\n"
     ]
    }
   ],
   "source": [
    "!sh src/ft_llama_lora/run_eval.sh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85a2ba06-ada9-438f-ac94-5c23c345fb65",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T08:00:01.714700Z",
     "iopub.status.busy": "2023-08-31T08:00:01.714356Z",
     "iopub.status.idle": "2023-08-31T08:00:02.991968Z",
     "shell.execute_reply": "2023-08-31T08:00:02.991319Z",
     "shell.execute_reply.started": "2023-08-31T08:00:01.714675Z"
    }
   },
   "outputs": [],
   "source": [
    "!pip list | grep peft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27a31922-28dd-4fcc-97b6-d3f5df9f9667",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-09-01T15:03:35.919124Z",
     "iopub.status.busy": "2023-09-01T15:03:35.918646Z",
     "iopub.status.idle": "2023-09-01T15:03:45.211696Z",
     "shell.execute_reply": "2023-09-01T15:03:45.211028Z",
     "shell.execute_reply.started": "2023-09-01T15:03:35.919103Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-09-01 23:03:39,154] [INFO] [real_accelerator.py:133:get_accelerator] Setting ds_accelerator to cuda (auto detect)\n",
      "2023-09-01 23:03:39.413034: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.11.0\n",
      "WARNING:tensorflow:Deprecation warnings have been disabled. Set TF_ENABLE_DEPRECATION_WARNINGS=1 to re-enable them.\n",
      "09/01/2023 23:03:40 - WARNING - __main__ - Process rank: 0, device: cuda:0, n_gpu: 1distributed training: True, 16-bits training: True\n",
      "[INFO|configuration_utils.py:667] 2023-09-01 23:03:40,663 >> loading configuration file /mnt/workspace/dataroot/models/michaelwzhu/Chinese-LlaMA2-chat-7B-sft-v0.3/config.json\n",
      "[INFO|configuration_utils.py:725] 2023-09-01 23:03:40,664 >> Model config LlamaConfig {\n",
      "  \"_name_or_path\": \"/mnt/workspace/dataroot/models/michaelwzhu/Chinese-LlaMA2-chat-7B-sft-v0.3\",\n",
      "  \"architectures\": [\n",
      "    \"LlamaForCausalLM\"\n",
      "  ],\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"silu\",\n",
      "  \"hidden_size\": 4096,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 11008,\n",
      "  \"max_length\": 4096,\n",
      "  \"max_position_embeddings\": 4096,\n",
      "  \"model_type\": \"llama\",\n",
      "  \"num_attention_heads\": 32,\n",
      "  \"num_hidden_layers\": 32,\n",
      "  \"num_key_value_heads\": 32,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pretraining_tp\": 1,\n",
      "  \"rms_norm_eps\": 1e-06,\n",
      "  \"rope_scaling\": null,\n",
      "  \"tie_word_embeddings\": false,\n",
      "  \"torch_dtype\": \"float16\",\n",
      "  \"transformers_version\": \"4.30.2\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 49954\n",
      "}\n",
      "\n",
      "[INFO|tokenization_utils_base.py:1821] 2023-09-01 23:03:40,664 >> loading file tokenizer.model\n",
      "[INFO|tokenization_utils_base.py:1821] 2023-09-01 23:03:40,664 >> loading file added_tokens.json\n",
      "[INFO|tokenization_utils_base.py:1821] 2023-09-01 23:03:40,664 >> loading file special_tokens_map.json\n",
      "[INFO|tokenization_utils_base.py:1821] 2023-09-01 23:03:40,664 >> loading file tokenizer_config.json\n",
      "09/01/2023 23:03:41 - INFO - datasets.builder - Using custom data configuration default-a0bfd06d086dfb24\n",
      "09/01/2023 23:03:41 - INFO - datasets.info - Loading Dataset Infos from /opt/conda/lib/python3.8/site-packages/datasets/packaged_modules/json\n",
      "09/01/2023 23:03:41 - INFO - datasets.builder - Overwrite dataset info from restored data version if exists.\n",
      "09/01/2023 23:03:41 - INFO - datasets.info - Loading Dataset info from /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4\n",
      "09/01/2023 23:03:41 - WARNING - datasets.builder - Found cached dataset json (/mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4)\n",
      "09/01/2023 23:03:41 - INFO - datasets.info - Loading Dataset info from /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4\n",
      "100%|████████████████████████████████████████████| 3/3 [00:00<00:00, 975.42it/s]\n",
      "09/01/2023 23:03:41 - INFO - datasets.arrow_dataset - Process #0 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-bcf63aa33d75f7c1_00000_of_00004.arrow\n",
      "09/01/2023 23:03:41 - INFO - datasets.arrow_dataset - Process #1 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-bcf63aa33d75f7c1_00001_of_00004.arrow\n",
      "09/01/2023 23:03:41 - INFO - datasets.arrow_dataset - Process #2 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-bcf63aa33d75f7c1_00002_of_00004.arrow\n",
      "09/01/2023 23:03:41 - INFO - datasets.arrow_dataset - Process #3 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-bcf63aa33d75f7c1_00003_of_00004.arrow\n",
      "09/01/2023 23:03:41 - INFO - datasets.arrow_dataset - Spawning 4 processes\n",
      "Running tokenizer on dataset (num_proc=4):   0%|  | 0/20 [00:00<?, ? examples/s]09/01/2023 23:03:41 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-bcf63aa33d75f7c1_00000_of_00004.arrow\n",
      "09/01/2023 23:03:41 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-bcf63aa33d75f7c1_00001_of_00004.arrow\n",
      "09/01/2023 23:03:41 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-bcf63aa33d75f7c1_00002_of_00004.arrow\n",
      "09/01/2023 23:03:41 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-bcf63aa33d75f7c1_00003_of_00004.arrow\n",
      "09/01/2023 23:03:41 - INFO - datasets.arrow_dataset - Concatenating 4 shards    \n",
      "09/01/2023 23:03:41 - INFO - datasets.arrow_dataset - Process #0 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-c21cd017f86517fe_00000_of_00004.arrow\n",
      "09/01/2023 23:03:41 - INFO - datasets.arrow_dataset - Process #1 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-c21cd017f86517fe_00001_of_00004.arrow\n",
      "09/01/2023 23:03:41 - INFO - datasets.arrow_dataset - Process #2 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-c21cd017f86517fe_00002_of_00004.arrow\n",
      "09/01/2023 23:03:41 - INFO - datasets.arrow_dataset - Process #3 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-c21cd017f86517fe_00003_of_00004.arrow\n",
      "09/01/2023 23:03:41 - INFO - datasets.arrow_dataset - Spawning 4 processes\n",
      "Running tokenizer on dataset (num_proc=4):   0%|  | 0/20 [00:00<?, ? examples/s]09/01/2023 23:03:41 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-c21cd017f86517fe_00000_of_00004.arrow\n",
      "09/01/2023 23:03:41 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-c21cd017f86517fe_00001_of_00004.arrow\n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-c21cd017f86517fe_00002_of_00004.arrow\n",
      "Running tokenizer on dataset (num_proc=4):  75%|▊| 15/20 [00:00<00:00, 132.94 ex09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-c21cd017f86517fe_00003_of_00004.arrow\n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Concatenating 4 shards    \n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Process #0 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-9ac3b016626aec7e_00000_of_00004.arrow\n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Process #1 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-9ac3b016626aec7e_00001_of_00004.arrow\n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Process #2 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-9ac3b016626aec7e_00002_of_00004.arrow\n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Process #3 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-9ac3b016626aec7e_00003_of_00004.arrow\n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Spawning 4 processes\n",
      "Running tokenizer on dataset (num_proc=4):   0%|  | 0/20 [00:00<?, ? examples/s]09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-9ac3b016626aec7e_00000_of_00004.arrow\n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-9ac3b016626aec7e_00001_of_00004.arrow\n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-9ac3b016626aec7e_00002_of_00004.arrow\n",
      "Running tokenizer on dataset (num_proc=4):  75%|▊| 15/20 [00:00<00:00, 129.45 ex09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-9ac3b016626aec7e_00003_of_00004.arrow\n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Concatenating 4 shards    \n",
      "tokenized_dataset:  DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 20\n",
      "    })\n",
      "    dev: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 20\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 20\n",
      "    })\n",
      "})\n",
      "[1, 29871, 31658, 30383, 13, 32237, 31138, 32380, 36655, 30214, 39313, 34339, 36655, 30275, 34534, 30210, 33942, 37110, 30214, 31666, 37887, 38920, 31149, 39990, 30952, 30383, 13, 36655, 32342, 30383, 13, 32822, 30383, 32593, 41049, 31639, 32269, 43434, 43095, 30210, 32027, 30882, 13, 32822, 30383, 38020, 33096, 30806, 36021, 32822, 31999, 38020, 32764, 32066, 32161, 32058, 30882, 13, 34339, 36655, 30383, 13, 33062, 30383, 31238, 32292, 30850, 32980, 33673, 34982, 43095, 13, 30682, 31333, 39990, 30952, 41133, 30383, 32009, 42147, 31751, 33942, 30214, 42147, 31751, 33942, 30214, 32395, 32237, 35230, 30333, 32932, 35358, 32262, 42147, 31751, 33942, 13, 33091, 30383, 13]\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Process #0 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-70bbacb8ba39a416_00000_of_00004.arrow\n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Process #1 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-70bbacb8ba39a416_00001_of_00004.arrow\n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Process #2 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-70bbacb8ba39a416_00002_of_00004.arrow\n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Process #3 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-70bbacb8ba39a416_00003_of_00004.arrow\n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Spawning 4 processes\n",
      "Grouping texts in chunks of 512 (num_proc=4):   0%| | 0/20 [00:00<?, ? examples/09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-70bbacb8ba39a416_00000_of_00004.arrow\n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-70bbacb8ba39a416_00001_of_00004.arrow\n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-70bbacb8ba39a416_00002_of_00004.arrow\n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-70bbacb8ba39a416_00003_of_00004.arrow\n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Concatenating 4 shards    \n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Process #0 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-119737197f4b101c_00000_of_00004.arrow\n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Process #1 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-119737197f4b101c_00001_of_00004.arrow\n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Process #2 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-119737197f4b101c_00002_of_00004.arrow\n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Process #3 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-119737197f4b101c_00003_of_00004.arrow\n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Spawning 4 processes\n",
      "Grouping texts in chunks of 512 (num_proc=4):   0%| | 0/20 [00:00<?, ? examples/09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-119737197f4b101c_00000_of_00004.arrow\n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-119737197f4b101c_00001_of_00004.arrow\n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-119737197f4b101c_00002_of_00004.arrow\n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-119737197f4b101c_00003_of_00004.arrow\n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Concatenating 4 shards    \n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Process #0 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-1ca7303015ba1c56_00000_of_00004.arrow\n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Process #1 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-1ca7303015ba1c56_00001_of_00004.arrow\n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Process #2 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-1ca7303015ba1c56_00002_of_00004.arrow\n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Process #3 will write at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-1ca7303015ba1c56_00003_of_00004.arrow\n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Spawning 4 processes\n",
      "Grouping texts in chunks of 512 (num_proc=4):   0%| | 0/20 [00:00<?, ? examples/09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-1ca7303015ba1c56_00001_of_00004.arrow\n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-1ca7303015ba1c56_00003_of_00004.arrow\n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-1ca7303015ba1c56_00000_of_00004.arrow\n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Caching processed dataset at /mnt/workspace/PromptCBLUE-data/hf_datasets_cache/json/default-a0bfd06d086dfb24/0.0.0/e347ab1c932092252e717ff3f949105a4dd28b27e842dd53157d2f72e276c2e4/cache-1ca7303015ba1c56_00002_of_00004.arrow\n",
      "09/01/2023 23:03:42 - INFO - datasets.arrow_dataset - Concatenating 4 shards    \n",
      "DatasetDict({\n",
      "    train: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 9\n",
      "    })\n",
      "    dev: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 9\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 7\n",
      "    })\n",
      "})\n",
      "{'input_ids': [1, 29871, 31658, 30383, 13, 33109, 30210, 34269, 32623, 30503, 37779, 38496, 35870, 35571, 34214, 30882, 13, 34269, 32623, 30383, 36120, 30429, 31313, 30743, 44027, 32612, 31313, 13, 37779, 38496, 30383, 32992, 30429, 31313, 44027, 32239, 32612, 31313, 13, 38631, 30383, 32409, 30413, 39611, 32097, 32009, 33738, 32635, 30214, 34149, 39611, 36174, 33738, 32635, 30214, 32211, 39611, 30214, 32409, 39611, 13, 33091, 30383, 13, 1, 29871, 31658, 30383, 13, 30505, 33885, 36655, 30275, 42582, 33885, 32624, 30214, 39733, 34128, 34033, 30214, 33942, 30214, 33790, 32752, 37303, 30214, 34128, 41133, 37110, 30383, 13, 43136, 35886, 34950, 32828, 30214, 30705, 36285, 32183, 43136, 37986, 32055, 13, 33091, 30383, 13, 1, 29871, 31658, 30383, 13, 32237, 36655, 32316, 30214, 42582, 33942, 31666, 31791, 32250, 31149, 39990, 30952, 30383, 13, 36655, 32342, 30383, 13, 32822, 30383, 30417, 33805, 45176, 32003, 42828, 42694, 39307, 43560, 31491, 31356, 33766, 13, 32822, 30383, 43340, 30214, 35029, 30705, 32054, 30406, 36690, 13, 34339, 36655, 30383, 13, 33062, 30383, 33805, 45176, 38323, 37569, 13, 39990, 30952, 38631, 30383, 32009, 42147, 31751, 33942, 30214, 42147, 31751, 33942, 30214, 32395, 32237, 35230, 30333, 32932, 35358, 32262, 42147, 31751, 33942, 13, 33091, 30383, 13, 1, 29871, 31658, 30383, 13, 31658, 36021, 36655, 32342, 30383, 13, 33062, 30383, 30685, 32953, 32992, 34086, 32243, 33982, 32262, 32671, 30882, 13, 32822, 30383, 30919, 31076, 13, 32822, 30383, 32992, 30392, 44572, 35564, 32399, 32027, 30882, 13, 32822, 30383, 32295, 35779, 32206, 32092, 30214, 30672, 32054, 37927, 32593, 32779, 31267, 32161, 33279, 36720, 32026, 30214, 33607, 32593, 33809, 30267, 13, 33062, 30383, 30392, 30210, 30214, 45175, 31390, 30755, 30666, 30743, 31977, 33533, 42215, 33932, 13, 32822, 30383, 37822, 30214, 29896, 30408, 43136, 35969, 30882, 13, 33062, 30383, 34589, 38231, 32278, 30214, 34605, 33396, 30408, 32278, 13, 32822, 30383, 33192, 30214, 32992, 32643, 32074, 33932, 38312, 30882, 13, 33062, 30383, 32271, 32032, 30659, 35639, 30214, 32410, 32852, 35374, 30214, 32471, 32613, 30666, 30743, 40901, 33633, 13, 33062, 30383, 32643, 32937, 13, 32822, 30383, 37822, 30214, 32764, 30392, 35250, 35131, 13, 32822, 30383, 34394, 30392, 32106, 33472, 30214, 37165, 30666, 30743, 40901, 33633, 13, 32822, 30383, 32346, 31999, 32992, 39519, 45062, 13, 33062, 30383, 41254, 32074, 32005, 33697, 30486, 33703, 30210, 13, 32822, 30383, 33192, 30214, 32306, 32074, 33697, 30486, 33703, 13, 33062, 30383, 33192, 30584, 32937, 13, 32822, 30383, 31076, 30214, 13, 32822, 30383, 32593, 30417, 32519, 32026, 32003, 36387, 35876, 32797, 31391, 37451, 30214, 39295, 30780, 30822, 30437, 39793, 33954, 30267, 13, 33062, 30383, 32013, 32243, 32243, 38615, 43204, 30257, 32026, 32055, 13, 32822, 30383, 38615, 30214, 36596, 30257, 32026, 13, 33062, 30383, 42215, 33932, 34105, 32306, 32749, 32027, 30882, 13, 32822, 30383, 37822, 30214, 32306, 32749, 33869, 32183, 13, 33062, 30383, 32937, 30214, 33318, 30584, 13, 32822, 30383, 30413, 31915, 32047, 13, 32822, 30383, 32746, 40901, 30210, 33684, 30214, 32236, 32749, 30780, 34618, 33472, 30743, 30214, 33808, 33072, 32468, 35250, 35131, 13, 33062, 30383, 32133, 32050, 30214, 32937, 30214, 30672, 37085, 32746, 30210, 30214, 33318, 30584, 13, 32822, 30383, 30413, 32912, 30584, 13, 32822, 30383, 35435, 32992, 32500, 33969, 33406, 30584, 13, 33062, 30383, 37840, 31522, 39652, 31658], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]}\n",
      "[INFO|modeling_utils.py:2265] 2023-09-01 23:03:42,862 >> Overriding torch_dtype=None with `torch_dtype=torch.float16` due to requirements of `bitsandbytes` to enable model loading in 8-bit or 4-bit. Pass your own torch_dtype to specify the dtype of the remaining non-linear layers or pass torch_dtype=torch.float16 to remove this warning.\n",
      "[INFO|modeling_utils.py:2575] 2023-09-01 23:03:42,862 >> loading weights file /mnt/workspace/dataroot/models/michaelwzhu/Chinese-LlaMA2-chat-7B-sft-v0.3/pytorch_model.bin.index.json\n",
      "[INFO|modeling_utils.py:1173] 2023-09-01 23:03:42,862 >> Instantiating LlamaForCausalLM model under default dtype torch.float16.\n",
      "[INFO|configuration_utils.py:577] 2023-09-01 23:03:42,863 >> Generate config GenerationConfig {\n",
      "  \"_from_model_config\": true,\n",
      "  \"bos_token_id\": 1,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"max_length\": 4096,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"transformers_version\": \"4.30.2\"\n",
      "}\n",
      "\n",
      "[INFO|modeling_utils.py:2690] 2023-09-01 23:03:42,988 >> Detected 8-bit loading: activating 8-bit loading for this model\n",
      "Traceback (most recent call last):\n",
      "  File \"src/ft_llama_lora/run_clm_pt_with_peft.py\", line 766, in <module>\n",
      "    main()\n",
      "  File \"src/ft_llama_lora/run_clm_pt_with_peft.py\", line 612, in main\n",
      "    model = LlamaForCausalLM.from_pretrained(\n",
      "  File \"/opt/conda/lib/python3.8/site-packages/transformers/modeling_utils.py\", line 2819, in from_pretrained\n",
      "    raise ValueError(\n",
      "ValueError: \n",
      "                        Some modules are dispatched on the CPU or the disk. Make sure you have enough GPU RAM to fit\n",
      "                        the quantized model. If you want to dispatch the model on the CPU or the disk while keeping\n",
      "                        these modules in 32-bit, you need to set `load_in_8bit_fp32_cpu_offload=True` and pass a custom\n",
      "                        `device_map` to `from_pretrained`. Check\n",
      "                        https://huggingface.co/docs/transformers/main/en/main_classes/quantization#offload-between-cpu-and-gpu\n",
      "                        for more details.\n",
      "                        \n"
     ]
    }
   ],
   "source": [
    "!sh src/ft_llama_lora/run_predict.sh\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "03766ada-d7f3-4dce-acb8-0b654363b0cb",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-09-01T02:13:31.788444Z",
     "iopub.status.busy": "2023-09-01T02:13:31.787958Z",
     "iopub.status.idle": "2023-09-01T02:13:31.997506Z",
     "shell.execute_reply": "2023-09-01T02:13:31.996960Z",
     "shell.execute_reply.started": "2023-09-01T02:13:31.788423Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "230M\toutput/promptcblue-llama-7b-pt-v0/checkpoint-2400\n",
      "230M\toutput/promptcblue-llama-7b-pt-v0/checkpoint-1700\n",
      "230M\toutput/promptcblue-llama-7b-pt-v0/checkpoint-800\n",
      "230M\toutput/promptcblue-llama-7b-pt-v0/checkpoint-1400\n",
      "230M\toutput/promptcblue-llama-7b-pt-v0/checkpoint-1300\n",
      "230M\toutput/promptcblue-llama-7b-pt-v0/checkpoint-600\n",
      "230M\toutput/promptcblue-llama-7b-pt-v0/checkpoint-2100\n",
      "230M\toutput/promptcblue-llama-7b-pt-v0/checkpoint-400\n",
      "230M\toutput/promptcblue-llama-7b-pt-v0/checkpoint-1100\n",
      "230M\toutput/promptcblue-llama-7b-pt-v0/checkpoint-700\n",
      "230M\toutput/promptcblue-llama-7b-pt-v0/checkpoint-200\n",
      "230M\toutput/promptcblue-llama-7b-pt-v0/checkpoint-100\n",
      "152K\toutput/promptcblue-llama-7b-pt-v0/runs\n",
      "230M\toutput/promptcblue-llama-7b-pt-v0/checkpoint-1900\n",
      "230M\toutput/promptcblue-llama-7b-pt-v0/checkpoint-2300\n",
      "230M\toutput/promptcblue-llama-7b-pt-v0/checkpoint-2200\n",
      "230M\toutput/promptcblue-llama-7b-pt-v0/checkpoint-300\n",
      "230M\toutput/promptcblue-llama-7b-pt-v0/checkpoint-1200\n",
      "230M\toutput/promptcblue-llama-7b-pt-v0/checkpoint-2000\n",
      "230M\toutput/promptcblue-llama-7b-pt-v0/checkpoint-1600\n",
      "230M\toutput/promptcblue-llama-7b-pt-v0/checkpoint-500\n",
      "230M\toutput/promptcblue-llama-7b-pt-v0/checkpoint-1500\n",
      "8.0K\toutput/promptcblue-llama-7b-pt-v0/.ipynb_checkpoints\n",
      "230M\toutput/promptcblue-llama-7b-pt-v0/checkpoint-1800\n",
      "230M\toutput/promptcblue-llama-7b-pt-v0/checkpoint-1000\n",
      "230M\toutput/promptcblue-llama-7b-pt-v0/checkpoint-900\n",
      "5.4G\toutput/promptcblue-llama-7b-pt-v0/\n"
     ]
    }
   ],
   "source": [
    "!du -h -d 1 output/promptcblue-llama-7b-pt-v0/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a59e88c6-9de4-4c55-b129-df27140476a7",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-09-01T14:41:27.145987Z",
     "iopub.status.busy": "2023-09-01T14:41:27.145632Z",
     "iopub.status.idle": "2023-09-01T14:41:36.949431Z",
     "shell.execute_reply": "2023-09-01T14:41:36.948851Z",
     "shell.execute_reply.started": "2023-09-01T14:41:27.145963Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20168f32be144b8181e506cf0c17d0cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "from transformers import (\n",
    "    CONFIG_MAPPING,\n",
    "    MODEL_FOR_CAUSAL_LM_MAPPING,\n",
    "    AutoConfig,\n",
    "    AutoModelForCausalLM,\n",
    "    LlamaForCausalLM,\n",
    "    LlamaTokenizer,\n",
    "    AutoTokenizer,\n",
    "    HfArgumentParser,\n",
    "    Trainer,\n",
    "    TrainingArguments,\n",
    "    default_data_collator,\n",
    "    is_torch_tpu_available,\n",
    "    set_seed, DataCollatorForSeq2Seq,\n",
    ")\n",
    "# config_kwargs = {\n",
    "#         \"cache_dir\": model_args.cache_dir,\n",
    "#         \"revision\": model_args.model_revision,\n",
    "#         \"use_auth_token\": True if model_args.use_auth_token else None,\n",
    "#     }\n",
    "model_name_or_path = \"./output/promptcblue-llama-7b-pt-v0/checkpoint-1500\"\n",
    "config_path=\"/mnt/workspace/dataroot/models/michaelwzhu/Chinese-LlaMA2-chat-7B-sft-v0.3\"\n",
    "config = AutoConfig.from_pretrained(config_path)#, **config_kwargs)\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    config_path,\n",
    "    from_tf=False,\n",
    "    config=config,\n",
    "    # cache_dir=model_args.cache_dir,\n",
    "    # revision=model_args.model_revision,\n",
    "    use_auth_token=False,\n",
    "    # torch_dtype=torch_dtype,\n",
    "    load_in_8bit=True,\n",
    "    device_map=\"auto\",\n",
    "    low_cpu_mem_usage=True\n",
    ")#.half()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "031e7437-7b92-44c0-90c4-173f99c84218",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-09-01T14:38:38.609298Z",
     "iopub.status.busy": "2023-09-01T14:38:38.608778Z",
     "iopub.status.idle": "2023-09-01T14:38:38.629416Z",
     "shell.execute_reply": "2023-09-01T14:38:38.628746Z",
     "shell.execute_reply.started": "2023-09-01T14:38:38.609275Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = LlamaTokenizer.from_pretrained(model_name_or_path, padding_side=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1960aed6-cb12-4623-aa43-7537bc798508",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "raw_datasets = load_dataset(\n",
    "    \"json\",\n",
    "    data_files={\n",
    "        \"dev\": \"/mnt/workspace/PromptCBLUE-data/dev20.jsonl\",\n",
    "        \"test\": \"/mnt/workspace/PromptCBLUE-data/testA20.jsonl\"\n",
    "    },\n",
    "    # cache_dir=\"/mnt/workspace/PromptCBLUE-data/hf_dataset_cache\",\n",
    "    use_auth_token=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a307a121-4a80-46b3-a974-42e8d4cc71d0",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-09-01T14:40:49.767441Z",
     "iopub.status.busy": "2023-09-01T14:40:49.767097Z",
     "iopub.status.idle": "2023-09-01T14:40:49.772637Z",
     "shell.execute_reply": "2023-09-01T14:40:49.772113Z",
     "shell.execute_reply.started": "2023-09-01T14:40:49.767419Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt_column = \"input\"\n",
    "response_column = \"target\"\n",
    "\n",
    "def tokenize_function(example, do_predict=True):\n",
    "    # print(example)\n",
    "    query = example[prompt_column]\n",
    "    response = example[response_column]\n",
    "    prompt = \"<s>问：\\n{}\\n答：\\n\".format(query.strip().replace(\"答：\", \"\").strip())\n",
    "\n",
    "    if do_predict:\n",
    "        result = tokenizer(prompt, padding=\"max_length\", truncation=True,\n",
    "                           max_length=512, add_special_tokens=False)\n",
    "        result[\"labels\"] = [-100] * len(result[\"input_ids\"])\n",
    "        return result\n",
    "    else:\n",
    "        answer = \"{}\\n</s>\".format(response.strip())\n",
    "        tokenized_prompt = tokenizer(prompt, add_special_tokens=False)\n",
    "        user_prompt_len = len(tokenized_prompt[\"input_ids\"])\n",
    "        result = tokenizer(text=prompt + answer, add_special_tokens=False)\n",
    "        result[\"labels\"] = [-100] * user_prompt_len + result[\"input_ids\"][user_prompt_len:]\n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e779aff6-5712-4917-b358-4ec1e83b90e4",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-09-01T14:41:01.138151Z",
     "iopub.status.busy": "2023-09-01T14:41:01.137795Z",
     "iopub.status.idle": "2023-09-01T14:41:01.478322Z",
     "shell.execute_reply": "2023-09-01T14:41:01.477692Z",
     "shell.execute_reply.started": "2023-09-01T14:41:01.138128Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f5afa9558ea42aa9b1b515ee50bb04e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset (num_proc=4):   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5958192a8f5849f5aaabd36281bd8843",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Running tokenizer on dataset (num_proc=4):   0%|          | 0/20 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenized_dataset:  DatasetDict({\n",
      "    dev: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 20\n",
      "    })\n",
      "    test: Dataset({\n",
      "        features: ['input_ids', 'attention_mask', 'labels'],\n",
      "        num_rows: 20\n",
      "    })\n",
      "})\n",
      "[2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 29871, 31658, 30383, 13, 33885, 34269, 30383, 30672, 42714, 29941, 30850, 34636, 36814, 30214, 29896, 30850, 30980, 31975, 30743, 30214, 30437, 34976, 32027, 13, 32465, 32316, 30383, 30919, 31076, 30214, 30919, 29896, 30534, 32406, 30850, 32981, 30936, 36814, 30214, 29906, 30534, 29906, 30850, 38431, 46047, 30980, 31975, 32454, 34300, 30743, 30267, 32307, 31733, 32009, 30952, 32125, 30214, 33539, 29906, 30534, 32352, 30850, 38431, 37864, 34428, 30980, 31975, 30214, 29941, 30534, 32114, 30850, 34647, 34976, 30743, 30214, 31356, 32214, 38954, 30919, 37864, 34428, 30210, 30214, 34419, 30392, 46047, 30210, 30267, 40843, 30503, 46047, 30980, 31975, 33173, 32529, 32225, 31117, 30214, 30392, 32009, 33029, 34976, 30210, 30267, 13, 34131, 34269, 30503, 32465, 32262, 32293, 30882, 13, 38631, 29901, 29871, 32293, 30214, 30413, 32293, 13, 33091, 30383, 13]\n",
      "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]\n"
     ]
    }
   ],
   "source": [
    "tokenized_dataset = raw_datasets.map(\n",
    "            tokenize_function,\n",
    "            batched=False,\n",
    "            num_proc=4,\n",
    "            remove_columns=[prompt_column, response_column, \"answer_choices\", \"task_type\", \"task_dataset\", \"sample_id\"],\n",
    "            load_from_cache_file=False,\n",
    "            # cache_file_names={k: os.path.join(data_args.dataset_cache_dir, f'tokenized.arrow') for k in raw_datasets},\n",
    "            desc=\"Running tokenizer on dataset\",\n",
    "        )\n",
    "print(\"tokenized_dataset: \", tokenized_dataset)\n",
    "print(tokenized_dataset[\"dev\"][3]['input_ids'])\n",
    "print(tokenized_dataset[\"dev\"][3]['labels'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "51e29ec2-0265-43ca-9ed5-fb66e9946815",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-09-01T14:39:15.111812Z",
     "iopub.status.busy": "2023-09-01T14:39:15.111466Z",
     "iopub.status.idle": "2023-09-01T14:39:15.116940Z",
     "shell.execute_reply": "2023-09-01T14:39:15.116439Z",
     "shell.execute_reply.started": "2023-09-01T14:39:15.111791Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input': '下面的搜索词和页面标签的意思有多相同？\\n搜索词：冬季上火了吃什么降火\\n页面标签：宝宝上火吃什么药降火\\n选项：完全不匹配或者没有参考价值，很少匹配有一些参考价值，部分匹配，完全匹配', 'target': '', 'answer_choices': ['完全不匹配或者没有参考价值', '很少匹配有一些参考价值', '部分匹配', '完全匹配'], 'task_type': 'nli', 'task_dataset': 'KUAKE-QTR', 'sample_id': 'test-24460'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': [2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 1, 29871, 31658, 30383, 13, 33109, 30210, 34269, 32623, 30503, 37779, 38496, 35870, 35571, 34214, 30882, 13, 34269, 32623, 30383, 36120, 30429, 31313, 30743, 44027, 32612, 31313, 13, 37779, 38496, 30383, 32992, 30429, 31313, 44027, 32239, 32612, 31313, 13, 38631, 30383, 32409, 30413, 39611, 32097, 32009, 33738, 32635, 30214, 34149, 39611, 36174, 33738, 32635, 30214, 32211, 39611, 30214, 32409, 39611, 13, 33091, 30383, 13], 'attention_mask': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'labels': [-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_function(raw_datasets['test'][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ae98542-2cc3-4f59-a487-58495fa785d0",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-09-01T14:43:35.555376Z",
     "iopub.status.busy": "2023-09-01T14:43:35.554735Z",
     "iopub.status.idle": "2023-09-01T14:43:35.588833Z",
     "shell.execute_reply": "2023-09-01T14:43:35.588303Z",
     "shell.execute_reply.started": "2023-09-01T14:43:35.555356Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   1,\n",
       "   29871,\n",
       "   31658,\n",
       "   30383,\n",
       "   13,\n",
       "   34069,\n",
       "   32561,\n",
       "   41933,\n",
       "   33812,\n",
       "   30882,\n",
       "   13,\n",
       "   43049,\n",
       "   32202,\n",
       "   40853,\n",
       "   13,\n",
       "   34269,\n",
       "   41933,\n",
       "   38631,\n",
       "   30383,\n",
       "   32418,\n",
       "   33286,\n",
       "   30214,\n",
       "   38024,\n",
       "   36438,\n",
       "   30214,\n",
       "   33992,\n",
       "   38141,\n",
       "   30214,\n",
       "   43585,\n",
       "   32267,\n",
       "   30214,\n",
       "   41274,\n",
       "   30214,\n",
       "   36490,\n",
       "   32423,\n",
       "   30214,\n",
       "   33885,\n",
       "   33358,\n",
       "   13,\n",
       "   33091,\n",
       "   30383,\n",
       "   13],\n",
       "  [2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   2,\n",
       "   1,\n",
       "   29871,\n",
       "   31658,\n",
       "   30383,\n",
       "   13,\n",
       "   31088,\n",
       "   32237,\n",
       "   30557,\n",
       "   34389,\n",
       "   33885,\n",
       "   39897,\n",
       "   42925,\n",
       "   30214,\n",
       "   39313,\n",
       "   36021,\n",
       "   37183,\n",
       "   36557,\n",
       "   32351,\n",
       "   30383,\n",
       "   13,\n",
       "   7520,\n",
       "   29940,\n",
       "   13079,\n",
       "   33062,\n",
       "   29992,\n",
       "   35461,\n",
       "   32079,\n",
       "   41131,\n",
       "   30767,\n",
       "   30682,\n",
       "   32596,\n",
       "   32437,\n",
       "   32522,\n",
       "   34128,\n",
       "   30419,\n",
       "   30847,\n",
       "   31475,\n",
       "   34773,\n",
       "   34480,\n",
       "   30429,\n",
       "   37131,\n",
       "   31605,\n",
       "   30330,\n",
       "   31843,\n",
       "   34773,\n",
       "   30592,\n",
       "   31391,\n",
       "   31016,\n",
       "   46721,\n",
       "   39509,\n",
       "   30409,\n",
       "   30214,\n",
       "   32039,\n",
       "   39610,\n",
       "   30952,\n",
       "   36962,\n",
       "   33274,\n",
       "   32080,\n",
       "   34138,\n",
       "   41214,\n",
       "   42961,\n",
       "   31138,\n",
       "   31859,\n",
       "   30267,\n",
       "   32000,\n",
       "   40717,\n",
       "   33062,\n",
       "   30330,\n",
       "   40508,\n",
       "   30330,\n",
       "   39393,\n",
       "   46119,\n",
       "   37802,\n",
       "   31580,\n",
       "   33062,\n",
       "   31184,\n",
       "   33444,\n",
       "   30406,\n",
       "   32437,\n",
       "   32522,\n",
       "   34128,\n",
       "   30267,\n",
       "   13,\n",
       "   32681,\n",
       "   30383,\n",
       "   37357,\n",
       "   32007,\n",
       "   30998,\n",
       "   36021,\n",
       "   37183,\n",
       "   36557,\n",
       "   32351,\n",
       "   34998,\n",
       "   30573,\n",
       "   31272,\n",
       "   32448,\n",
       "   43160,\n",
       "   30503,\n",
       "   36557,\n",
       "   43160,\n",
       "   38230,\n",
       "   30685,\n",
       "   36312,\n",
       "   32351,\n",
       "   30214,\n",
       "   40090,\n",
       "   32039,\n",
       "   41033,\n",
       "   30210,\n",
       "   32431,\n",
       "   30705,\n",
       "   32148,\n",
       "   33751,\n",
       "   39897,\n",
       "   42925,\n",
       "   30214,\n",
       "   32993,\n",
       "   32157,\n",
       "   30998,\n",
       "   42925,\n",
       "   32204,\n",
       "   33730,\n",
       "   37110,\n",
       "   30503,\n",
       "   32234,\n",
       "   38227,\n",
       "   32425,\n",
       "   30214,\n",
       "   30953,\n",
       "   32054,\n",
       "   30998,\n",
       "   32070,\n",
       "   32148,\n",
       "   32019,\n",
       "   31767,\n",
       "   31986,\n",
       "   30214,\n",
       "   32426,\n",
       "   32001,\n",
       "   38482,\n",
       "   36557,\n",
       "   35641,\n",
       "   31608,\n",
       "   38640,\n",
       "   30505,\n",
       "   36021,\n",
       "   37183,\n",
       "   36557,\n",
       "   30685,\n",
       "   36312,\n",
       "   32351,\n",
       "   30275,\n",
       "   30214,\n",
       "   31838,\n",
       "   32285,\n",
       "   30319,\n",
       "   43160,\n",
       "   30392,\n",
       "   32448,\n",
       "   43160,\n",
       "   30214,\n",
       "   32285,\n",
       "   30319,\n",
       "   43160,\n",
       "   30392,\n",
       "   36557,\n",
       "   43160,\n",
       "   30267,\n",
       "   32115,\n",
       "   32448,\n",
       "   43160,\n",
       "   30214,\n",
       "   30948,\n",
       "   32448,\n",
       "   33933,\n",
       "   32350,\n",
       "   30573,\n",
       "   30015,\n",
       "   30392,\n",
       "   30024,\n",
       "   30594,\n",
       "   30214,\n",
       "   30998,\n",
       "   31415,\n",
       "   30780,\n",
       "   41316,\n",
       "   30319,\n",
       "   43160,\n",
       "   32019,\n",
       "   41320,\n",
       "   33933,\n",
       "   31391,\n",
       "   36557,\n",
       "   30214,\n",
       "   30948,\n",
       "   32448,\n",
       "   33933,\n",
       "   32350,\n",
       "   30573,\n",
       "   30015,\n",
       "   31191,\n",
       "   30024,\n",
       "   30594,\n",
       "   30214,\n",
       "   30998,\n",
       "   31415,\n",
       "   30780,\n",
       "   41053,\n",
       "   30319,\n",
       "   43160,\n",
       "   32019,\n",
       "   41320,\n",
       "   33933,\n",
       "   31391,\n",
       "   36557,\n",
       "   30267,\n",
       "   41610,\n",
       "   33289,\n",
       "   43160,\n",
       "   35808,\n",
       "   30573,\n",
       "   32001,\n",
       "   8977,\n",
       "   30214,\n",
       "   34570,\n",
       "   33178,\n",
       "   30578,\n",
       "   31559,\n",
       "   30383,\n",
       "   37290,\n",
       "   29874,\n",
       "   5513,\n",
       "   12154,\n",
       "   29908,\n",
       "   30214,\n",
       "   32112,\n",
       "   43160,\n",
       "   33812,\n",
       "   30214,\n",
       "   32062,\n",
       "   43160,\n",
       "   32510,\n",
       "   32448,\n",
       "   43160,\n",
       "   703,\n",
       "   29907,\n",
       "   1159,\n",
       "   37165,\n",
       "   36557,\n",
       "   43160,\n",
       "   703,\n",
       "   29928,\n",
       "   1159,\n",
       "   31608,\n",
       "   37290,\n",
       "   29890,\n",
       "   5513,\n",
       "   3626,\n",
       "   2701,\n",
       "   29908,\n",
       "   30214,\n",
       "   32112,\n",
       "   30457,\n",
       "   30824,\n",
       "   31263,\n",
       "   40259,\n",
       "   30214,\n",
       "   34777,\n",
       "   33749,\n",
       "   36021,\n",
       "   37183,\n",
       "   32723,\n",
       "   32097,\n",
       "   35260,\n",
       "   32148,\n",
       "   30210,\n",
       "   30457,\n",
       "   30824,\n",
       "   31263,\n",
       "   30214,\n",
       "   32112,\n",
       "   32448,\n",
       "   29914,\n",
       "   36557,\n",
       "   43160,\n",
       "   35568,\n",
       "   30214,\n",
       "   30457,\n",
       "   30824,\n",
       "   31263,\n",
       "   32234,\n",
       "   31611,\n",
       "   34998,\n",
       "   30743,\n",
       "   29953,\n",
       "   30832,\n",
       "   30383,\n",
       "   29908,\n",
       "   35260,\n",
       "   32503,\n",
       "   613,\n",
       "   376,\n",
       "   32418,\n",
       "   34128,\n",
       "   613,\n",
       "   376,\n",
       "   42502,\n",
       "   30406,\n",
       "   31180,\n",
       "   613,\n",
       "   376,\n",
       "   32418,\n",
       "   33286,\n",
       "   613,\n",
       "   376,\n",
       "   33444,\n",
       "   40683,\n",
       "   30834,\n",
       "   613,\n",
       "   376,\n",
       "   32255,\n",
       "   32263,\n",
       "   29908,\n",
       "   31608,\n",
       "   37290,\n",
       "   29883,\n",
       "   5513,\n",
       "   1188,\n",
       "   936,\n",
       "   29918,\n",
       "   2674,\n",
       "   29908,\n",
       "   30214,\n",
       "   32062,\n",
       "   33963,\n",
       "   30457,\n",
       "   30824,\n",
       "   31263,\n",
       "   33798,\n",
       "   34844,\n",
       "   32234,\n",
       "   30419,\n",
       "   30683,\n",
       "   30959,\n",
       "   30573,\n",
       "   392,\n",
       "   29892,\n",
       "   470,\n",
       "   29892,\n",
       "   1870,\n",
       "   30214,\n",
       "   30948,\n",
       "   32190,\n",
       "   30457,\n",
       "   30824,\n",
       "   31263,\n",
       "   30210,\n",
       "   30502,\n",
       "   30354,\n",
       "   29966,\n",
       "   43054,\n",
       "   30594,\n",
       "   34844,\n",
       "   32234,\n",
       "   30573,\n",
       "   1870,\n",
       "   30409,\n",
       "   30267,\n",
       "   36212,\n",
       "   29897,\n",
       "   32606,\n",
       "   36021,\n",
       "   37183,\n",
       "   36557,\n",
       "   32351,\n",
       "   30651,\n",
       "   31566,\n",
       "   30898,\n",
       "   37275,\n",
       "   34216,\n",
       "   38100,\n",
       "   30573,\n",
       "   32001,\n",
       "   40259,\n",
       "   30267,\n",
       "   13,\n",
       "   33091,\n",
       "   30383,\n",
       "   13]],\n",
       " 'attention_mask': [[0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1],\n",
       "  [0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   0,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1,\n",
       "   1]],\n",
       " 'labels': [[-100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100],\n",
       "  [-100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100,\n",
       "   -100]]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset['dev'][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2d8f945c-6600-4dbb-9b19-c511316461ea",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-09-01T14:45:47.216484Z",
     "iopub.status.busy": "2023-09-01T14:45:47.215845Z",
     "iopub.status.idle": "2023-09-01T14:45:47.223459Z",
     "shell.execute_reply": "2023-09-01T14:45:47.222987Z",
     "shell.execute_reply.started": "2023-09-01T14:45:47.216462Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    2,     2,     2,  ..., 33091, 30383,    13],\n",
       "         [    2,     2,     2,  ..., 33091, 30383,    13]]),\n",
       " 'attention_mask': tensor([[0, 0, 0,  ..., 1, 1, 1],\n",
       "         [0, 0, 0,  ..., 1, 1, 1]]),\n",
       " 'labels': tensor([[-100, -100, -100,  ..., -100, -100, -100],\n",
       "         [-100, -100, -100,  ..., -100, -100, -100]])}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import copy\n",
    "import torch\n",
    "inputs = copy(tokenized_dataset['dev'][0:2])\n",
    "for k in inputs.keys():\n",
    "    inputs[k] = torch.LongTensor(inputs[k])\n",
    "inputs\n",
    "                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2990383-6c09-46c9-a10d-75492ac384cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-09-01T14:46:01.897640Z",
     "iopub.status.busy": "2023-09-01T14:46:01.897027Z",
     "iopub.status.idle": "2023-09-01T14:56:05.849301Z",
     "shell.execute_reply": "2023-09-01T14:56:05.848738Z",
     "shell.execute_reply.started": "2023-09-01T14:46:01.897617Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/transformers/generation/utils.py:1353: UserWarning: Using `max_length`'s default (4096) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/transformers/generation/utils.py:1452: UserWarning: You are calling .generate() with the `input_ids` being on a device type different than your model's device. `input_ids` is on cpu, whereas the model is on cuda. You may experience unexpected behaviors or slower generation. Please make sure that you have put `input_ids` to the correct device by calling for example input_ids = input_ids.to('cuda') before running `.generate()`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[    2,     2,     2,  ..., 45276, 33805, 34713],\n",
       "        [    2,     2,     2,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.generate(**inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ece639cc-0579-4cce-ac4b-698990f00274",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-08-31T07:27:46.820756Z",
     "iopub.status.busy": "2023-08-31T07:27:46.820250Z",
     "iopub.status.idle": "2023-08-31T07:37:57.461889Z",
     "shell.execute_reply": "2023-08-31T07:37:57.461189Z",
     "shell.execute_reply.started": "2023-08-31T07:27:46.820735Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [10:10<00:00, 30.53s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "data = raw_datasets['test']\n",
    "res_all = []\n",
    "for prompt in tqdm(data, total=len(data)):\n",
    "    inputs = tokenizer(prompt['input'], return_tensors=\"pt\").to(torch.device('cuda:0'))\n",
    "    res_all.append(model.generate(**inputs, max_length=512))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "26fffe86-0837-4622-8139-e2bd360783bd",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-08-31T07:39:01.632829Z",
     "iopub.status.busy": "2023-08-31T07:39:01.632475Z",
     "iopub.status.idle": "2023-08-31T07:39:01.686956Z",
     "shell.execute_reply": "2023-08-31T07:39:01.686114Z",
     "shell.execute_reply.started": "2023-08-31T07:39:01.632810Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 \n",
      " <s>下面的搜索词和页面标签的意思有多相同？\n",
      "搜索词：冬季上火了吃什么降火\n",
      "页面标签：宝宝上火吃什么药降火\n",
      "选项：完全不匹配或者没有参考价值，很少匹配有一些参考价值，部分匹配，完全匹配\n",
      "解释：\n",
      "选项1：没有参考价值，因为“冬天上火了吃什么降火”是一个模糊的问题，没有明确的答案。\n",
      "选项2：没有参考价值，因为“宝宝上火吃什么药降火”是一个模糊的问题，没有明确的答案。\n",
      "选项3：没有参考价值，因为“冬天上火了吃什么降火”和“宝宝上火吃什么药降火”都是模糊的问题，没有明确的答案。\n",
      "选项4：没有参考价值，因为“冬天上火了吃什么降火”和“宝宝上火吃什么药降火”都是模糊的问题，没有明确的答案。\n",
      "选项5：没有参考价值，因为“冬天上火了吃什么降火”和“宝宝上火吃什么药降火”都是模糊的问题，没有明确的答案。\n",
      "选项6：没有参考价值，因为“冬天上火了吃什么降火”和“宝宝上火吃什么药降火”都是模糊的问题，没有明确的答案。\n",
      "选项7：没有参考价值，因为“冬天上火了吃什么降火”和“宝宝上火吃什么药降火”都是模糊的问题，没有明确的答案。\n",
      "选项8：没有参考价值，因为“冬天上火了吃什么降火”和“宝宝上火吃什么药降火”都是模糊的问题，没有明确的答案。\n",
      "选项9：没有参考价值，因为“冬天上火了吃什么降火”和“宝宝上火吃什么药降火”都是模糊的问题，没有明确的答案。\n",
      "选项10：没有参考价值，因为“冬天上火了吃什么降火”和“宝宝上火吃什么药降火”都是模糊的问题，没有明确的答案。\n",
      "选项11：没有参考价值，因为“冬天上火了吃什么降火”和“宝宝上火吃什么药降火”都是模糊的问题，没有明确的答案。\n",
      "选项12：没有参考价值，因为“冬天上火了吃什么降火”和“宝宝上火吃什么药降火”都是模糊的问题，没有明确的答案。\n",
      "选项13：没有参考价值，因为“冬天上火了\n",
      "1 \n",
      " <s>在医疗对话中找出医疗操作，具体的药物名称，症状，医学检查检验，药物类别实体：\n",
      "大便中有粘液，化验一下大便常规吧。\n",
      "医生：好的，我们需要进行一些检查。请稍等片刻。\n",
      "（医生开始检查病人的身体）\n",
      "医生：（看到病人的血液）这似乎是血脂过高的症状。我们需要进行一些血液检查。\n",
      "（医生开始进行血液检查）\n",
      "医生：（看到病人的血液）这似乎是血脂过高的症状。我们需要进行一些血液检查。\n",
      "（医生开始进行血液检查）\n",
      "医生：（看到病人的血液）这似乎是血脂过高的症状。我们需要进行一些血液检查。\n",
      "（医生开始进行血液检查）\n",
      "医生：（看到病人的血液）这似乎是血脂过高的症状。我们需要进行一些血液检查。\n",
      "（医生开始进行血液检查）\n",
      "医生：（看到病人的血液）这似乎是血脂过高的症状。我们需要进行一些血液检查。\n",
      "（医生开始进行血液检查）\n",
      "医生：（看到病人的血液）这似乎是血脂过高的症状。我们需要进行一些血液检查。\n",
      "（医生开始进行血液检查）\n",
      "医生：（看到病人的血液）这似乎是血脂过高的症状。我们需要进行一些血液检查。\n",
      "（医生开始进行血液检查）\n",
      "医生：（看到病人的血液）这似乎是血脂过高的症状。我们需要进行一些血液检查。\n",
      "（医生开始进行血液检查）\n",
      "医生：（看到病人的血液）这似乎是血脂过高的症状。我们需要进行一些血液检查。\n",
      "（医生开始进行血液检查）\n",
      "医生：（看到病人的血液）这似乎是血脂过高的症状。我们需要进行一些血液检查。\n",
      "（医生开始进行血液检查）\n",
      "医生：（看到病人的血液）这似乎是血脂过高的症状。我们需要进行一些血液检查。\n",
      "（医生开始进行血液检查）\n",
      "医生：（看到病人的血液）这似乎是血脂过高的症状。我们需要进行一些血液检查。\n",
      "（医生开始进行血液检查）\n",
      "医生：（看到病人的血液）这似乎是血脂过高的症状。我们需要进行一些血液检查。\n",
      "（医生开始进行血液检查）\n",
      "医生：（看到病人的\n",
      "2 \n",
      " <s> 根据对话内容，找出症状并判别其阴阳性：\n",
      "对话历史：\n",
      "医生：有鼻涕可以口服小儿氨酚黄那敏\n",
      "医生：喘，雾化需要用激素\n",
      "当前对话：\n",
      "患者：鼻涕像是过敏\n",
      "阴阳性选项：没有患有该症状，患有该症状，无法根据上下文确定病人是否患有该症状。</s>\n",
      "3 \n",
      " <s>问诊对话历史：\n",
      "患者：二个月宝宝的大便颜色是否正常？\n",
      "医生：你好\n",
      "医生：宝宝是母乳喂养吗？\n",
      "医生：为了更好的提供服务，我需要询问您几个与病症相关的问题，感谢您配合。\n",
      "患者：是的，这两天夜里加了两顿配方奶\n",
      "医生：嗯，1天大便几次？\n",
      "患者：基本上三天一次，有时候隔天一次\n",
      "医生：哦，宝宝精神吃奶好吗？\n",
      "患者：之前都是金黄色，今天有点不一样，不知道是不是加了奶粉的原因\n",
      "患者：精神好的\n",
      "医生：嗯，考虑是消化不良\n",
      "医生：有可能是受凉，或者是加了奶粉的原因\n",
      "医生：建议给宝宝腹部保暖\n",
      "患者：一直都吃着益生菌的\n",
      "医生：哦，继续吃益生菌\n",
      "患者：哦！好的\n",
      "医生：好，\n",
      "医生：您有任何问题可以随时和我联系或留言，我看到后会第一时间回复。\n",
      "患者：这个便便看上去没啥大问题吧\n",
      "医生：看上去，没有什么大问题\n",
      "患者：配方奶还能继续喝吗？\n",
      "医生：嗯，继续喝观察一下\n",
      "患者：好的，谢谢！\n",
      "医生：不客气\n",
      "医生：注意奶粉的温度，不要喝到后面凉了，那样也会导致消化不良\n",
      "患者：这样啊，好的，我一定会注意的，谢谢！\n",
      "医生：不谢！\n",
      "医生：祝宝宝健康快乐成长！\n",
      "患者：我还想顺便问一下，我得了产后荨麻疹，差不多一个月了，一直在吃维C和葡萄糖酸钙，可还是时好时坏的，还有什么办法吗？就是半夜起，白天几乎就没了\n",
      "医生：可以看中医吃中药调理一下\n",
      "患者：可我还在喂奶中\n",
      "医生：嗯，喂奶可以吃中药的\n",
      "患者：哦！好吧，那我去看看中医\n",
      "医生：看医生的时候，和医生说一下，是母乳期，医生就会开相应的药\n",
      "患者：好的，非常感谢您！\n",
      "医生：不客气，有事联系\n",
      "患者：????\n",
      "医生：好，拜拜\n",
      "根据上述对话，给出诊疗报告\n",
      "说明：诊疗报告分为主诉, 现病史, 辅助检查, 既往史, 诊断, 建议这六个章节。\n",
      "主诉：患者在医生的诊疗中，提出了自己的问题，包括宝宝大\n",
      "4 \n",
      " <s>以下文本包含医疗三元组，请找出并填写：\n",
      "如果这些研究被进一步证实将为了解SMA的发病机制迈出重要一步。 （二）SMA-Ⅱ型 肌肉病理形态改变类似SMA-Ⅰ型，但大组萎缩肌纤维不常见，而同型肌群化现象则更为突出。\n",
      "其中的三元组类型是：传播途径，遗传因素，手术治疗，筛查，预防，实验室检查，发病年龄，侵及周围组织转移的症状，相关（导致），并发症，多发地区，多发群体，死亡率，放射治疗，预后生存率，临床表现，发病率，发病机制，风险评估因素，发病性别倾向，相关（症状），多发季节，同义词，病理分型，预后状况，内窥镜检查，外侵部位，鉴别诊断，阶段，相关（转化），病理生理，高危因素，组织学检查，就诊科室，化疗，发病部位，病理分析，病理学，病理学分析，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学诊断，病理学\n",
      "5 \n",
      " <s> 医疗搜索：皮肤发黄，暗黄，怎么办\n",
      "回答内容：皮肤发黄一般有2种情况，要先弄清楚自己的原因再对症下药。指导意见1.角质层太厚，皮肤透明感差，加上东方人天生的偏黄肤色，就会看起来黄黄的。解决原因当然就是定期去角质，以及补水，让角质层吸饱水，看起来就会透亮的。2.皮肤血液循环不好，暗沉发黄。可以定期使用按摩膏，加强皮肤的血液循环，排出毒素，皮肤自然就会明亮。\n",
      "上述搜索和回答是否相关？\n",
      "选项: 相关，不相关。</s>\n",
      "6 \n",
      " <s>请识别以下搜索query的意图类型：\n",
      "鹦鹉滋养丸用什么做的\n",
      "搜索意图选项：注意事项，指标解读，就医建议，医疗费用，治疗方案，病情诊断，后果表述，病因分析，药物使用，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，药物剂量，药物效果，药物副作用，药物使用方法，\n",
      "7 \n",
      " <s> 使用给定的病历文本，列出下述临床发现事件属性：\n",
      "2019.07.01我院行鼻咽喉镜提示声带息肉，鼻咽癌放疗后，今为求复查，今日以“ 鼻咽癌 ”收入我科。\n",
      "事件抽取说明：临床发现事件由主体词，发生状态，描述词和解剖部位组成。\n",
      "事件属性：\n",
      "1. 主体词：“我院”\n",
      "2. 发生状态：“行鼻咽喉镜提示声带息肉”\n",
      "3. 描述词：“鼻咽癌”\n",
      "4. 解剖部位：“鼻咽”\n",
      "因此，该病历文本的临床发现事件属性为：“我院”，“鼻咽癌”，“鼻咽”。</s>\n",
      "8 \n",
      " <s> 问诊对话历史：\n",
      "患者：连续发烧5天，使用美林后退烧，药效过后又发烧，多是在38.5左右，有时会到39.6。先吃了三天头孢，又换了阿奇霉素吃了2天，还是不好。血常规正常，c反略高，宝宝牙龈肿胀比较厉害！到底是什么引起的发烧？\n",
      "医生：你好\n",
      "患者：你好\n",
      "医生：宝宝现在体温是逐步下降吗？\n",
      "患者：没有啊\n",
      "患者：用了退烧药才降\n",
      "医生：还是可以达到39度以上吗？\n",
      "患者：药效过了又高起来\n",
      "医生：嗯，宝宝精神食欲好吗？\n",
      "患者：头上一直贴着退热贴，没有到39度\n",
      "患者：下午退烧药没吃\n",
      "患者：精神可以\n",
      "患者：吃东西一直都不太好，尤其牙龈肿了更不是很好\n",
      "医生：嗯，就是说虽然体温高，高的程度有没有逐步下降\n",
      "患者：好像没有啊\n",
      "医生：哦，如果是这种情况，有可能是口服药控制不住炎症，建议给宝宝静脉输液治疗\n",
      "患者：这种情况是细菌还是病毒感染呢？\n",
      "医生：考虑是细菌感染引起的\n",
      "患者：那牙龈肿是为什么呢\n",
      "患者：牙齿边上还有血的样子\n",
      "医生：细菌感染，可以引起牙龈肿胀的\n",
      "患者：可是血常规看上去正常啊\n",
      "患者：就c反稍微高点\n",
      "医生：嗯，c反应蛋白高就考虑细菌感染\n",
      "患者：好的，谢谢\n",
      "根据上述对话，给出诊疗报告\n",
      "说明：诊疗报告分为主诉, 现病史, 辅助检查, 既往史, 诊断, 建议这六个章节。\n",
      "主诉：患者出现发热、牙龈肿胀等症状，需要进行治疗。\n",
      "现病史：患者过去三天头孢，之后再服用阿奇霉素，但症状依然存在，病情持续。\n",
      "辅助检查：患者的血常规正常，但c反略高，说明患者可能患有细菌感染。\n",
      "我們史：患者过去两次服用退烧药，但症状依然存在，病情持续。\n",
      "诊断：患者可能患有细菌感染引起的牙龈肿胀。\n",
      "建议：建议给宝宝静脉输液治疗，并进行相关辅助检查。</s>\n",
      "9 \n",
      " <s>在姨妈前经常自慰会不会月经失调\n",
      "请根据提供的搜索query，选出正确的意图类型：\n",
      "类型选项：病情诊断，就医建议，病因分析，疾病描述，指标解读，注意事项，医疗费用，治疗方案，功效作用，后果表述，药物使用，药物副作用，药物使用方法，药物使用注意事项，药物使用效果，药物使用效果评估，药物使用效果评估方法，药物使用效果评估结果，药物使用效果评估结果解释，药物使用效果评估结果解释解释，药物使用效果评估结果解释解释解释，药物使用效果评估结果解释解释解释解释，药物使用效果评估结果解释解释解释解释解释，药物使用效果评估结果解释解释解释解释解释，药物使用效果评估结果解释解释解释解释解释，药物使用效果评估结果解释解释解释解释解释，药物使用效果评估结果解释解释解释解释解释，药物使用效果评估结果解释解释解释解释，药物使用效果评估结果解释解释解释解释，药物使用效果评估结果解释解释解释，药物使用效果评估结果解释解释，药物使用效果评估结果解释，药物使用效果评估结果解释，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果评估结果，药物使用效果\n",
      "10 \n",
      " <s> 对话历史：\n",
      "医生：今天有呕吐吗？\n",
      "患者：今天呕吐没有\n",
      "当前对话：\n",
      "患者：昨天呕吐两次\n",
      "根据上述对话历史，当前对话中症状有哪些？这些症状的阴阳性是？\n",
      "选项：没有患有该症状，患有该症状，无法根据上下文确定病人是否患有该症状。\n",
      "答案：没有患有该症状。</s>\n",
      "11 \n",
      " <s> 临床发现事件抽取：\n",
      "5.（阑尾）：浆膜及壁见高级别浆液性癌累及。\n",
      "说明：临床发现事件的主体词包含发生状态，描述词和解剖部位这三种属性，其中描述词和解剖部位可能有多个值，但只有其中一个值才能构成事件。</s>\n",
      "12 \n",
      " <s>孩子鼻涕先着凉的时候可能比较明显！一定别着凉\n",
      "问题：在医生与患者的对话中，有哪些实体被标记为症状，药物类别，具体的药物名称，医疗操作？\n",
      "医生：你最近有没有出现咳嗽、喉咙疼痛、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、咳嗽、\n",
      "13 \n",
      " <s> 以下回答内容是否与这里的医疗搜索相关？\n",
      "医疗搜索：脸上挤出虫子是螨虫吗\n",
      "回答内容：不建议使用浓盐水擦脸，去除螨虫可以使用除螨皂，或者是硫磺皂。可用消毒液碘伏，然后再用消炎的红霉素软膏涂抹。用洁面乳洗脸，清洁皮肤后，可以在痘痘上涂抹芦荟胶。平时使用补水保湿面膜，尽量不要使用化妆品。多喝水，多吃瓜果蔬菜。不要共用脸盆、毛巾等，这样就会远离螨虫的侵扰。\n",
      "选项: 相关，不相关\n",
      "解释：虽然回答内容提到了去除螨虫的方法，但并不涉及到医疗搜索，因为答案并没有提到任何医疗术语或术语。</s>\n",
      "14 \n",
      " <s> 以下是关于患者病历的描述：患者自发病以来， 精神差 ， 食欲差 ， 睡眠欠佳 ， 大便如上述 ， 小便如常 ， 体重无明显变化 。\n",
      "问题：请提取病历文本中的临床发现事件及其属性\n",
      "说明：临床发现事件由主体词，发生状态，描述词和解剖部位组成，例如：“患者自乙号以来， 精神差 ， 食欲差 ， 睡眠欠佳 ， 体重无明显变化 。”\n",
      "提取方法：\n",
      "1. 确定患者的症状和症状的类型，例如：精神差，食欲差，睡眠欠佳，体重无明显变化。\n",
      "2. 确定患者的症状出现的时间，例如：患者自乙号以来。\n",
      "3. 提取患者的症状描述，例如：“精神差 ， 食欲差 ， 睡眠欠佳 ， 体重无明显变化 。”\n",
      "4. 提取患者的症状的属性，例如：“精神差”，“食欲差”，“睡眠欠佳”，“体重无明显变化”。\n",
      "提取结果：\n",
      "患者自乙号以来， 精神差 ， 食欲差 ， 睡眠欠佳 ， 体重无明显变化。\n",
      "临床发现事件：\n",
      "患者自乙号以来， 精神差 ， 食欲差 ， 睡眠欠佳 ， 体重无明显变化。\n",
      "事件属性：\n",
      "- 精神差\n",
      "- 食欲差\n",
      "- 睡眠欠佳\n",
      "- 体重无明显变化</s>\n",
      "15 \n",
      " <s>请确认以下两句话是否意思相同。\n",
      "“艾滋感染后要多少天会出现症状”，“急性艾滋病早期症状多少天会出现”。\n",
      "选项：相同，不同\n",
      "答：相同。\n",
      "“艾滋病的症状是什么”，“艾滋病的症状是什么”。\n",
      "选项：相同，不同\n",
      "答：相同。\n",
      "“艾滋病的症状是什么”，“艾滋病的症状是什么”。\n",
      "选项：相同，不同\n",
      "答：相同。\n",
      "“艾滋病的症状是什么”，“艾滋病的症状是什么”。\n",
      "选项：相同，不同\n",
      "答：不同。\n",
      "“艾滋病的症状是什么”，“艾滋病的症状是什么”。\n",
      "选项：相同，不同\n",
      "答：不同。\n",
      "“艾滋病的症状是什么”，“艾滋病的症状是什么”。\n",
      "选项：相同，不同\n",
      "答：不同。\n",
      "“艾滋病的症状是什么”，“艾滋病的症状是什么”。\n",
      "选项：相同，不同\n",
      "答：不同。\n",
      "“艾滋病的症状是什么”，“艾滋病的症状是什么”。\n",
      "选项：相同，不同\n",
      "答：不同。\n",
      "“艾滋病的症状是什么”，“艾滋病的症状是什么”。\n",
      "选项：相同，不同\n",
      "答：不同。\n",
      "“艾滋病的症状是什么”，“艾滋病的症状是什么”。\n",
      "选项：相同，不同\n",
      "答：不同。\n",
      "“艾滋病的症状是什么”，“艾滋病的症状是什么”。\n",
      "选项：相同，不同\n",
      "答：不同。\n",
      "“艾滋病的症状是什么”，“艾滋病的症状是什么”。\n",
      "选项：相同，不同\n",
      "答：不同。\n",
      "“艾滋病的症状是什么”，“艾滋病的症状是什么”。\n",
      "选项：相同，不同\n",
      "答：不同。\n",
      "“艾滋病的症状是什么”，“艾滋病的症状是什么”。\n",
      "选项：相同，不同\n",
      "答：不同。\n",
      "“艾滋病的症状是什么”，“艾滋病的症状是什么”。\n",
      "选项：相同，不同\n",
      "答：不同。\n",
      "“艾滋病的症状是什么”，“艾滋病的症状是什么”。\n",
      "选项：相同，不同\n",
      "答：不同。\n",
      "“艾滋病的症状是什么”，“艾滋病的症状是什么”。\n",
      "选项：相同，不同\n",
      "答：不同。\n",
      "“艾\n",
      "16 \n",
      " <s>根据以下文本，判断适用的临床试验筛选标准类型：\n",
      "5、非汉族人群。\n",
      "选项：疾病分期，设备，知情同意，治疗或手术，种族，年龄，病例来源，献血，诊断，实验室检查，受体状态，参与其它试验，研究者决定，肿瘤进展，依存性，护理，器官组织状态，特殊病人特征，饮食，风险评估，成瘾行为，锻炼，睡眠，过敏耐受，能力，含有多个类别，药物，性别，疾病，健康群体，口腔相关，体征(医生检测），症状(患者感受)，预期寿命，数据可及性，残疾群体，酒精使用，读写能力，吸烟状况，伦理审查，性取向，居住情况，教育情况，怀孕相关，药物副作用，药物治疗，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗效果，药物副作用，药物治疗\n",
      "17 \n",
      " <s>临床发现事件抽取：\n",
      "2019-04患者行胸腹部、盆腔ct提示：腹主动脉主动脉分叉下方类圆形低密度影，淋巴管囊肿？局限性扩张肠管？盆腔内、阴道及直肠残端片状软组织密度影，与双侧输尿管下段粘连；腹腔少许积液，腹膜增厚；盆腔内内淋巴结显示。\n",
      "说明：临床发现事件的主体词包含发生状态，描述词和解剖部位这三种属性，其中描述词和解剖部位可能有多个值，但总的来说，事件的主体词和描述词是描述事件发生的情况，而解剖部位是描述事件发生的部位。\n",
      "例如，“腹主动脉搏”是事件主体词，描述词是“收缩”，解剖部位是“腹主动脉搏”。\n",
      "在CT扫描中，“腹主动脉搏”是事件主体词，描述词是“收缩”，解剖部位是“腹主动脉搏”。\n",
      "在CT扫描中，“腹主动脉搏”是事件主体词，描述词是“收缩”，解剖部位是“腹主动脉搏”。\n",
      "在CT扫描中，“腹主动脉搏”是事件主体词，描述词是“收缩”，解剖部位是“腹主动脉搏”。\n",
      "在CT扫描中，“腹主动脉搏”是事件主体词，描述词是“收缩”，解剖部位是“腹主动脉搏”。\n",
      "在CT扫描中，“腹主动脉搏”是事件主体词，描述词是“收缩”，解剖部位是“腹主动脉搏”。\n",
      "在CT扫描中，“腹主动脉搏”是事件主体词，描述词是“收缩”，解剖部位是“腹主动脉搏”。\n",
      "在CT扫描中，“腹主动脉搏”是事件主体词，描述词是“收缩”，解剖部位是“腹主动脉搏”。\n",
      "在CT扫描中，“腹主动脉搏”是事件主体词，描述词是“收缩”，解剖部位是“腹主动脉搏”。\n",
      "在CT扫描中，“腹主动脉搏”是事件主体词，描述词是“收缩”，解剖部位是“腹主动脉搏”。\n",
      "在CT扫描中，“腹主动脉搏”是事件主体词，描述词是“收缩”，解剖部位是“腹\n",
      "18 \n",
      " <s> 临床发现事件抽取：2018-2-23患者开始出现呼吸困难，稍活动或平卧时即出现气紧、胸闷，不能耐受平卧，静息、斜卧位即缓解，无咳嗽、咳痰、胸痛、心悸、气喘。\n",
      "说明：临床发现事件的主体词包含发生状态，描述词和解剖部位这三种属性，其中描述词和解剖部位可能有多个值，但其中一个值是主要描述。\n",
      "解释：这个事件事件是指患者在运动或休息时出现呼吸困难，表现为气紧、胸闷等症状，无法承受平卧或静息，斜卧位则缓解症状。</s>\n",
      "19 \n",
      " <s> “脑供血不足吃什么药”，“脑供血不足吃什么药好”。\n",
      "这两个查询的语义关系是怎样的呢？\n",
      "选项：完全一致，后者是前者的语义子集，后者是前者的语义父集，语义无直接关联。</s>\n"
     ]
    }
   ],
   "source": [
    "for i,res in enumerate(res_all):\n",
    "    d = tokenizer.batch_decode(res)\n",
    "    print(i, '\\n', d[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "19a68e65-737e-4117-8520-61e9ae4bc8b2",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-08-31T07:04:21.645428Z",
     "iopub.status.busy": "2023-08-31T07:04:21.644737Z",
     "iopub.status.idle": "2023-08-31T07:04:24.508335Z",
     "shell.execute_reply": "2023-08-31T07:04:24.507775Z",
     "shell.execute_reply.started": "2023-08-31T07:04:21.645409Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"辨别下列对话中提及的症状，并判断其阴阳性：\\n对话历史：\\n患者：您怀疑有点支气管炎？\\n医生：如果检查单纯支气管炎可以口服氨溴索，肺力咳\\n当前对话：\\n医生：如果检查有肺炎建议输液治疗\\n症状阴阳性选项如下：没有患有该症状，患有该症状，无法根据上下文确定病人是否患有该症状\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").to(torch.device('cuda:0'))\n",
    "res = model.generate(**inputs, max_length=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2fe3941a-34c5-475f-8b3c-c17ab9f2e387",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-08-31T07:04:43.666231Z",
     "iopub.status.busy": "2023-08-31T07:04:43.665609Z",
     "iopub.status.idle": "2023-08-31T07:04:43.670637Z",
     "shell.execute_reply": "2023-08-31T07:04:43.670181Z",
     "shell.execute_reply.started": "2023-08-31T07:04:43.666209Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s> 辨别下列对话中提及的症状，并判断其阴阳性：\\n对话历史：\\n患者：您怀疑有点支气管炎？\\n医生：如果检查单纯支气管炎可以口服氨溴索，肺力咳\\n当前对话：\\n医生：如果检查有肺炎建议输液治疗\\n症状阴阳性选项如下：没有患有该症状，患有该症状，无法根据上下文确定病人是否患有该症状。</s>']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.batch_decode(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "960f3ecb-9e0e-4f26-b667-28f43e7730db",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-08-31T07:16:38.595461Z",
     "iopub.status.busy": "2023-08-31T07:16:38.594957Z",
     "iopub.status.idle": "2023-08-31T07:16:38.599765Z",
     "shell.execute_reply": "2023-08-31T07:16:38.599145Z",
     "shell.execute_reply.started": "2023-08-31T07:16:38.595440Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': '请问是什么意图类型？\\n癫痫怎么治愈\\n搜索意图选项：治疗方案，病情诊断，指标解读，病因分析，注意事项，功效作用，医疗费用',\n",
       " 'target': '治疗方案',\n",
       " 'answer_choices': ['治疗方案', '病情诊断', '指标解读', '病因分析', '注意事项', '功效作用', '医疗费用'],\n",
       " 'task_type': 'cls',\n",
       " 'task_dataset': 'KUAKE-QIC',\n",
       " 'sample_id': 'dev-35851'}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets['dev'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "86d3949a-5304-4483-826d-2450a51df491",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-31T07:05:18.009921Z",
     "iopub.status.busy": "2023-08-31T07:05:18.009236Z",
     "iopub.status.idle": "2023-08-31T07:05:18.016893Z",
     "shell.execute_reply": "2023-08-31T07:05:18.016348Z",
     "shell.execute_reply.started": "2023-08-31T07:05:18.009899Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1, 29871, 46243, 38997, 36655, 30275, 39822, 30210, 33942, 30214,\n",
       "         31666, 33933, 31149, 39990, 30952, 30383,    13, 36655, 32342, 30383,\n",
       "            13, 33062, 30383, 32593, 35403, 32852, 31541, 32047, 31624, 32868,\n",
       "         30882,    13, 32822, 30383, 32042, 32752, 37784, 31541, 32047, 31624,\n",
       "         32868, 32003, 42828, 39307, 46994, 31836, 30214, 34326, 31074, 39939,\n",
       "            13, 34339, 36655, 30383,    13, 32822, 30383, 32042, 32752, 30417,\n",
       "         34326, 32868, 32346, 31573, 32828, 32418,    13, 33942, 39990, 30952,\n",
       "         38631, 34001, 30383, 32009, 42147, 31751, 33942, 30214, 42147, 31751,\n",
       "         33942, 30214, 32395, 32237, 35230, 30333, 32932, 35358, 32262, 42147,\n",
       "         31751, 33942]], device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],\n",
       "       device='cuda:0')}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "82b70805-fc3b-421a-9fa6-72698514a78b",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-09-01T03:17:28.561743Z",
     "iopub.status.busy": "2023-09-01T03:17:28.561408Z",
     "iopub.status.idle": "2023-09-01T03:17:28.580574Z",
     "shell.execute_reply": "2023-09-01T03:17:28.580052Z",
     "shell.execute_reply.started": "2023-09-01T03:17:28.561719Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<jsonlines.Writer at 0x7f9968532f10 wrapping 'output.jsonl'>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jsonlines as jl\n",
    "f = jl.open('output.jsonl', 'w')\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78d16f9d-bdae-4ee0-99dd-d23723cf6e3a",
   "metadata": {
    "ExecutionIndicator": {
     "show": true
    },
    "execution": {
     "iopub.execute_input": "2023-09-01T03:19:35.524742Z",
     "iopub.status.busy": "2023-09-01T03:19:35.524407Z",
     "iopub.status.idle": "2023-09-01T03:19:35.527887Z",
     "shell.execute_reply": "2023-09-01T03:19:35.527296Z",
     "shell.execute_reply.started": "2023-09-01T03:19:35.524721Z"
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "f.write_all([{\"a\": \"res\"}, {\"b\": \"res\"}])\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198959e8-e784-44dc-a66c-3031d37adb74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
